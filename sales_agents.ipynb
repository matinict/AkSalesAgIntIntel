{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "MULTI-AGENT SALES INTELLIGENCE SYSTEM - AKIJ RESOURCE\n",
    "AI Agent & Agentic Intelligence Specialist Project\n",
    "Submitted by: Abdul Matin\n",
    "Organization: Akij Resource\n",
    "Date: November 2025\n",
    "=============================================================================\n",
    "\n",
    "This Jupyter Notebook demonstrates:\n",
    "1. Four Analytical Frameworks (Descriptive, Diagnostic, Predictive, Prescriptive)\n",
    "2. Multi-Agent Architecture using LangChain\n",
    "3. Agentic Intelligence with autonomous reasoning\n",
    "4. n8n Integration capability\n",
    "5. Conversational AI interface\n",
    "\n",
    "Currency: Bangladeshi Taka (à§³)\n",
    "Regions: Bangladesh Divisions (Dhaka, Chittagong, Rangpur, Khulna, Mymensingh, Rajshahi, Sylhet, Barisal)\n",
    "Products: Complete Akij Resource Product Portfolio (80+ Products)\n",
    "\n",
    "Run all cells sequentially to see the complete system in action.\n",
    "=============================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701b72a",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 1: SETUP & DEPENDENCIES\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4272edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"INSTALLING DEPENDENCIES...\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb98196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install in Google Colab or local Jupyter\n",
    "!pip install -q langchain langchain-openai pandas numpy plotly python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f45e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedbfb1",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 2: SALES DATA GENERATION - AKIJ PRODUCTS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982de97",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING HIERARCHICAL SALES DATA - AKIJ RESOURCE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cb9c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SalesDataGenerator:\n",
    "    \"\"\"Generate realistic sales dataset with complete Akij Resource product portfolio\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_sales_data(num_records: int = 4000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate synthetic sales data with Akij product categories organized by business divisions\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Complete Akij Resource Product Portfolio organized by Business Division\n",
    "        akij_products = {\n",
    "            'Beverages & Food': [\n",
    "                'Mojo', 'Frutika (Juice)', 'Speed (Energy Drink)', 'Clemon', 'Twing', 'Lemu', \n",
    "                'Royal Tiger', 'Spa Drinking Water', 'Yummy Lassi', 'Farm Fresh Milk (UHT)', \n",
    "                'Farm Fresh Ghee', 'Akij Daily Spices', 'Akij Daily Edible Oil', 'Akij Tea',\n",
    "                'Aafi Snacks (Chanachur)', 'O\\'Potato Chips', 'Happy Times Jam', \n",
    "                'Bakeman\\'s Biscuits', 'Funtastic Chocolate', 'Akij Flour (Atta)', \n",
    "                'Akij Maida', 'Akij Suji', 'Akij Muri (Puffed Rice)', 'Essential Chinigura Rice',\n",
    "                'Akij Bakers Bread', 'Akij Bakers Bun', 'Akij Bakers Cake'\n",
    "            ],\n",
    "            'Building & Construction': [\n",
    "                'Akij Cement (PCC/CEM-I)', 'Akij Ceramics Tiles (Wall/Floor/Stair)', \n",
    "                'Kathena Tiles', 'Sierra Tiles', 'Espacio Tiles', 'Rosa Sanitaryware',\n",
    "                'Akij Board (Particle Board/MDF)', 'Akij Door (Laminated)', 'Akij Door (Solid)',\n",
    "                'Akij Pipes & Fittings', 'Akij Buildtech', 'Akij Rebar (TMT)'\n",
    "            ],\n",
    "            'FMCG & Household': [\n",
    "                'Max Wash Detergent Powder', 'Dish Master (Liquid)', 'Dish Master (Bar)',\n",
    "                'Fantastik Air Freshener', 'H&H Hand Wash', 'Mum Mum Baby Diaper',\n",
    "                'Akij Daily Home Care Products', 'Akij Plastics Furniture', \n",
    "                'Akij Plastics Household Items'\n",
    "            ],\n",
    "            'Industrial & Other': [\n",
    "                'Akij Jute Yarn', 'Akij Jute Sacks', 'Akij Textile Woven Fabric', \n",
    "                'Akij Textile Denim', 'Akij Tableware (Porcelain)', \n",
    "                'Akij Motors Electric Bike', 'Akij Motors Three-Wheeler',\n",
    "                'AKIJ Power Light LED Bulb', 'AKIJ Fan (Ceiling Fan)', \n",
    "                'AKIJ AURA Switch', 'AKIJ DELIGHT Socket', 'Akij Electrical Cables',\n",
    "                'AKIJ Circuit Breaker (MCB)', 'Akij BIAX Films (BOPET)', \n",
    "                'Akij BIAX Films (CPP)', 'Akij Printing & Packaging',\n",
    "                'Akij Pharma Medicine', 'Akij Footwear', 'BONN Bicycle', 'B\\'FIRE Bicycle'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Flatten to get all products and create division mapping\n",
    "        all_products = []\n",
    "        product_to_division = {}\n",
    "        \n",
    "        for division, products in akij_products.items():\n",
    "            all_products.extend(products)\n",
    "            for product in products:\n",
    "                product_to_division[product] = division\n",
    "        \n",
    "        # Total products\n",
    "        total_products = len(all_products)\n",
    "        print(f\"ğŸ“¦ Total Akij Products: {total_products}\")\n",
    "        print(f\"ğŸ¢ Business Divisions: {len(akij_products)}\")\n",
    "        \n",
    "        # Create weighted distribution for products\n",
    "        # Beverages & Food: 40%, Building & Construction: 30%, FMCG: 20%, Industrial: 10%\n",
    "        division_weights = {\n",
    "            'Beverages & Food': 0.40,\n",
    "            'Building & Construction': 0.30,\n",
    "            'FMCG & Household': 0.20,\n",
    "            'Industrial & Other': 0.10\n",
    "        }\n",
    "        \n",
    "        # Calculate individual product weights\n",
    "        product_weights = []\n",
    "        for product in all_products:\n",
    "            division = product_to_division[product]\n",
    "            division_weight = division_weights[division]\n",
    "            num_products_in_division = len(akij_products[division])\n",
    "            product_weight = division_weight / num_products_in_division\n",
    "            product_weights.append(product_weight)\n",
    "        \n",
    "        # Normalize weights\n",
    "        product_weights = np.array(product_weights)\n",
    "        product_weights = product_weights / product_weights.sum()\n",
    "        \n",
    "        # Other dimensions\n",
    "        segments = ['Enterprise', 'SMB', 'Individual', 'Government', 'Retail Distributor', 'Wholesaler']\n",
    "        regions = ['Dhaka', 'Chittagong', 'Rangpur', 'Khulna', 'Mymensingh', 'Rajshahi', 'Sylhet', 'Barisal']\n",
    "        channels = ['Online', 'Retail Store', 'Wholesale', 'Direct Sales', 'Distributor Network']\n",
    "        \n",
    "        # Generate date range - up to today (November 5, 2025)\n",
    "        # end_date = datetime(2025, 11, 5)  # Today's date\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=730)  # 2 years of historical data\n",
    "        total_days = (end_date - start_date).days + 1\n",
    "        dates = [start_date + timedelta(days=x) for x in range(total_days)]\n",
    "        \n",
    "        # Create base data\n",
    "        data = {\n",
    "            'transaction_id': [f'AKJ{str(i).zfill(7)}' for i in range(1, num_records + 1)],\n",
    "            'date': np.random.choice(dates, num_records),\n",
    "            'product': np.random.choice(all_products, num_records, p=product_weights),\n",
    "            'customer_segment': np.random.choice(segments, num_records, p=[0.20, 0.25, 0.25, 0.08, 0.12, 0.10]),\n",
    "            'region': np.random.choice(regions, num_records, p=[0.28, 0.20, 0.10, 0.12, 0.08, 0.10, 0.07, 0.05]),\n",
    "            'sales_channel': np.random.choice(channels, num_records, p=[0.25, 0.25, 0.20, 0.15, 0.15]),\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Add business division column\n",
    "        df['business_division'] = df['product'].map(product_to_division)\n",
    "        \n",
    "        # Add realistic business metrics based on product type and division\n",
    "        \n",
    "        # Base revenue varies by division\n",
    "        base_revenue = np.random.uniform(500, 50000, num_records)\n",
    "        \n",
    "        # Building & Construction has highest revenue per transaction\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'Building & Construction',\n",
    "            base_revenue * np.random.uniform(2.0, 3.5, num_records),\n",
    "            base_revenue\n",
    "        )\n",
    "        \n",
    "        # Industrial products have high revenue\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'Industrial & Other',\n",
    "            df['revenue'] * np.random.uniform(1.5, 2.5, num_records),\n",
    "            df['revenue']\n",
    "        )\n",
    "        \n",
    "        # Beverages & Food have moderate revenue but high volume\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'Beverages & Food',\n",
    "            df['revenue'] * np.random.uniform(0.6, 1.2, num_records),\n",
    "            df['revenue']\n",
    "        )\n",
    "        \n",
    "        # FMCG has lower individual transaction value\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'FMCG & Household',\n",
    "            df['revenue'] * np.random.uniform(0.5, 1.0, num_records),\n",
    "            df['revenue']\n",
    "        )\n",
    "        \n",
    "        # Enterprise, Government and Wholesaler segments have higher transaction values\n",
    "        df['revenue'] = df['revenue'] * np.where(df['customer_segment'] == 'Enterprise', 1.5, 1.0)\n",
    "        df['revenue'] = df['revenue'] * np.where(df['customer_segment'] == 'Government', 1.4, 1.0)\n",
    "        df['revenue'] = df['revenue'] * np.where(df['customer_segment'] == 'Wholesaler', 1.3, 1.0)\n",
    "        \n",
    "        # Dhaka and Chittagong have higher revenue (major economic hubs)\n",
    "        df['revenue'] = df['revenue'] * np.where(df['region'].isin(['Dhaka', 'Chittagong']), 1.3, 1.0)\n",
    "        \n",
    "        # Add quantity based on product division\n",
    "        # FMCG and Beverages & Food have higher quantities\n",
    "        df['quantity'] = np.where(\n",
    "            df['business_division'].isin(['Beverages & Food', 'FMCG & Household']),\n",
    "            np.random.randint(100, 1000, num_records),\n",
    "            np.random.randint(1, 100, num_records)\n",
    "        )\n",
    "        \n",
    "        # Building materials have medium quantities\n",
    "        df['quantity'] = np.where(\n",
    "            df['business_division'] == 'Building & Construction',\n",
    "            np.random.randint(10, 200, num_records),\n",
    "            df['quantity']\n",
    "        )\n",
    "        \n",
    "        df['unit_price'] = df['revenue'] / df['quantity']\n",
    "        \n",
    "        # Cost varies by product division and realistic profit margins\n",
    "        # Beverages & Food: 25-35% margin\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'Beverages & Food',\n",
    "            df['revenue'] * np.random.uniform(0.65, 0.75, num_records),\n",
    "            df['revenue'] * np.random.uniform(0.50, 0.70, num_records)\n",
    "        )\n",
    "        \n",
    "        # Building & Construction: 30-40% margin\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'Building & Construction',\n",
    "            df['revenue'] * np.random.uniform(0.60, 0.70, num_records),\n",
    "            df['cost']\n",
    "        )\n",
    "        \n",
    "        # FMCG: 20-30% margin (competitive market)\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'FMCG & Household',\n",
    "            df['revenue'] * np.random.uniform(0.70, 0.80, num_records),\n",
    "            df['cost']\n",
    "        )\n",
    "        \n",
    "        # Industrial: 35-45% margin\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'Industrial & Other',\n",
    "            df['revenue'] * np.random.uniform(0.55, 0.65, num_records),\n",
    "            df['cost']\n",
    "        )\n",
    "        \n",
    "        df['profit'] = df['revenue'] - df['cost']\n",
    "        df['profit_margin'] = (df['profit'] / df['revenue']) * 100\n",
    "        \n",
    "        # Add temporal dimensions\n",
    "        df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "        df['quarter'] = pd.to_datetime(df['date']).dt.quarter\n",
    "        df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "        df['month_name'] = pd.to_datetime(df['date']).dt.strftime('%B')\n",
    "        df['week'] = pd.to_datetime(df['date']).dt.isocalendar().week\n",
    "        \n",
    "        # Add seasonal variations\n",
    "        # Beverages peak in summer (April-July)\n",
    "        df.loc[(df['business_division'] == 'Beverages & Food') & \n",
    "               (df['product'].str.contains('Mojo|Frutika|Speed|Clemon|Twing|Lemu|Spa', case=False, na=False)) & \n",
    "               (df['month'].isin([4, 5, 6, 7])), 'revenue'] *= 1.4\n",
    "        \n",
    "        # Building materials peak in dry season (November-March)\n",
    "        df.loc[(df['business_division'] == 'Building & Construction') & \n",
    "               (df['month'].isin([11, 12, 1, 2, 3])), 'revenue'] *= 1.3\n",
    "        \n",
    "        # FMCG products peak during Eid and festive seasons (March-April, August-September)\n",
    "        df.loc[(df['business_division'] == 'FMCG & Household') & \n",
    "               (df['month'].isin([3, 4, 8, 9])), 'revenue'] *= 1.2\n",
    "        \n",
    "        # Online and Direct Sales have slightly higher margins\n",
    "        df.loc[df['sales_channel'].isin(['Online', 'Direct Sales']), 'profit_margin'] *= 1.08\n",
    "        \n",
    "        # Recalculate profit after seasonal adjustments\n",
    "        df['profit'] = df['revenue'] - df['cost']\n",
    "        df['profit_margin'] = (df['profit'] / df['revenue']) * 100\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f641a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "print(\"\\nğŸ”„ Generating sales data...\")\n",
    "sales_data = SalesDataGenerator.generate_sales_data(num_records=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34eeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nâœ… Generated {len(sales_data):,} sales transactions\")\n",
    "print(f\"ğŸ“… Date Range: {sales_data['date'].min().date()} to {sales_data['date'].max().date()}\")\n",
    "print(f\"ğŸ“† Report Date: {datetime.now().strftime('%B %d, %Y')} (Today)\")\n",
    "print(f\"â±ï¸  Data Coverage: 2 years ({sales_data['date'].nunique()} days)\")\n",
    "print(f\"ğŸ’° Total Revenue: à§³{sales_data['revenue'].sum():,.2f}\")\n",
    "print(f\"ğŸ’µ Total Profit: à§³{sales_data['profit'].sum():,.2f}\")\n",
    "print(f\"ğŸ“Š Average Margin: {sales_data['profit_margin'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e98502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ¢ BUSINESS DIVISIONS:\")\n",
    "division_summary = sales_data.groupby('business_division').agg({\n",
    "    'revenue': 'sum',\n",
    "    'transaction_id': 'count'\n",
    "}).round(2)\n",
    "division_summary.columns = ['Total Revenue (à§³)', 'Transactions']\n",
    "print(division_summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f99347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ“¦ TOP 15 PRODUCTS BY REVENUE:\")\n",
    "top_products = sales_data.groupby('product')['revenue'].sum().sort_values(ascending=False).head(15)\n",
    "for i, (product, revenue) in enumerate(top_products.items(), 1):\n",
    "    print(f\"  {i:2d}. {product:.<50} à§³{revenue:>12,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c67c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸŒ REVENUE BY REGION:\")\n",
    "region_summary = sales_data.groupby('region')['revenue'].sum().sort_values(ascending=False)\n",
    "for region, revenue in region_summary.items():\n",
    "    pct = (revenue / sales_data['revenue'].sum()) * 100\n",
    "    print(f\"  {region:.<25} à§³{revenue:>12,.2f} ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4063fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ“Š Sample Data Preview:\")\n",
    "print(sales_data[['transaction_id', 'date', 'product', 'business_division', 'region', 'revenue', 'profit_margin']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "sales_data.to_csv('akij_sales_data.csv', index=False)\n",
    "print(\"\\nâœ… Data saved to 'akij_sales_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2861b4a",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 3: AGENT 1 - DESCRIPTIVE ANALYTICS (What has happened?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ccc56",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 1: DESCRIPTIVE ANALYTICS - What has happened?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867cbfb4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DescriptiveAgent:\n",
    "    \"\"\"\n",
    "    Descriptive Agent analyzes historical data to answer: \"What has happened?\"\n",
    "    - Summarizes past performance\n",
    "    - Identifies patterns and trends\n",
    "    - Provides comprehensive data overview\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "    \n",
    "    def analyze(self) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive descriptive analysis\"\"\"\n",
    "        \n",
    "        # Overall metrics\n",
    "        total_revenue = float(self.data['revenue'].sum())\n",
    "        total_profit = float(self.data['profit'].sum())\n",
    "        total_transactions = len(self.data)\n",
    "        avg_transaction_value = float(self.data['revenue'].mean())\n",
    "        avg_profit_margin = float(self.data['profit_margin'].mean())\n",
    "        total_quantity = int(self.data['quantity'].sum())\n",
    "        \n",
    "        # Time-based analysis\n",
    "        date_range = {\n",
    "            \"start\": str(self.data['date'].min().date()),\n",
    "            \"end\": str(self.data['date'].max().date()),\n",
    "            \"days\": (self.data['date'].max() - self.data['date'].min()).days,\n",
    "            \"report_date\": datetime.now().strftime('%B %d, %Y')\n",
    "        }\n",
    "        \n",
    "        # Business Division analysis\n",
    "        division_revenue = self.data.groupby('business_division')['revenue'].sum().sort_values(ascending=False)\n",
    "        division_profit = self.data.groupby('business_division')['profit'].sum().sort_values(ascending=False)\n",
    "        division_margin = self.data.groupby('business_division')['profit_margin'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        top_division = division_revenue.idxmax()\n",
    "        division_breakdown = {\n",
    "            div: {\n",
    "                'revenue': round(float(division_revenue[div]), 2),\n",
    "                'profit': round(float(division_profit[div]), 2),\n",
    "                'avg_margin': round(float(division_margin[div]), 2)\n",
    "            }\n",
    "            for div in division_revenue.index\n",
    "        }\n",
    "        \n",
    "        # Product analysis (Top 15)\n",
    "        product_revenue = self.data.groupby('product')['revenue'].sum().sort_values(ascending=False).head(15)\n",
    "        top_product = product_revenue.idxmax()\n",
    "        product_breakdown = product_revenue.to_dict()\n",
    "        \n",
    "        # Regional analysis\n",
    "        region_revenue = self.data.groupby('region')['revenue'].sum().sort_values(ascending=False)\n",
    "        region_transactions = self.data.groupby('region')['transaction_id'].count()\n",
    "        top_region = region_revenue.idxmax()\n",
    "        region_breakdown = {\n",
    "            reg: {\n",
    "                'revenue': round(float(region_revenue[reg]), 2),\n",
    "                'transactions': int(region_transactions[reg])\n",
    "            }\n",
    "            for reg in region_revenue.index\n",
    "        }\n",
    "        \n",
    "        # Segment analysis\n",
    "        segment_revenue = self.data.groupby('customer_segment')['revenue'].sum().sort_values(ascending=False)\n",
    "        top_segment = segment_revenue.idxmax()\n",
    "        segment_breakdown = segment_revenue.to_dict()\n",
    "        \n",
    "        # Channel analysis\n",
    "        channel_revenue = self.data.groupby('sales_channel')['revenue'].sum().sort_values(ascending=False)\n",
    "        channel_margin = self.data.groupby('sales_channel')['profit_margin'].mean()\n",
    "        top_channel = channel_revenue.idxmax()\n",
    "        channel_breakdown = {\n",
    "            chan: {\n",
    "                'revenue': round(float(channel_revenue[chan]), 2),\n",
    "                'avg_margin': round(float(channel_margin[chan]), 2)\n",
    "            }\n",
    "            for chan in channel_revenue.index\n",
    "        }\n",
    "        \n",
    "        # Monthly trends\n",
    "        monthly_revenue = self.data.groupby('month')['revenue'].sum().to_dict()\n",
    "        monthly_volume = self.data.groupby('month')['transaction_id'].count().to_dict()\n",
    "        \n",
    "        # Quarterly performance\n",
    "        quarterly_revenue = self.data.groupby('quarter')['revenue'].sum().to_dict()\n",
    "        quarterly_profit = self.data.groupby('quarter')['profit'].sum().to_dict()\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Descriptive Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"overall_metrics\": {\n",
    "                \"total_revenue\": round(total_revenue, 2),\n",
    "                \"total_profit\": round(total_profit, 2),\n",
    "                \"total_transactions\": total_transactions,\n",
    "                \"total_quantity_sold\": total_quantity,\n",
    "                \"avg_transaction_value\": round(avg_transaction_value, 2),\n",
    "                \"avg_profit_margin\": round(avg_profit_margin, 2)\n",
    "            },\n",
    "            \"date_range\": date_range,\n",
    "            \"top_performers\": {\n",
    "                \"division\": top_division,\n",
    "                \"product\": top_product,\n",
    "                \"region\": top_region,\n",
    "                \"segment\": top_segment,\n",
    "                \"channel\": top_channel\n",
    "            },\n",
    "            \"hierarchical_breakdown\": {\n",
    "                \"by_division\": division_breakdown,\n",
    "                \"by_product_top15\": {k: round(v, 2) for k, v in product_breakdown.items()},\n",
    "                \"by_region\": region_breakdown,\n",
    "                \"by_segment\": {k: round(v, 2) for k, v in segment_breakdown.items()},\n",
    "                \"by_channel\": channel_breakdown\n",
    "            },\n",
    "            \"temporal_trends\": {\n",
    "                \"monthly_revenue\": {k: round(v, 2) for k, v in monthly_revenue.items()},\n",
    "                \"monthly_volume\": monthly_volume,\n",
    "                \"quarterly_revenue\": {k: round(v, 2) for k, v in quarterly_revenue.items()},\n",
    "                \"quarterly_profit\": {k: round(v, 2) for k, v in quarterly_profit.items()}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    DESCRIPTIVE ANALYTICS REPORT                            â•‘\n",
    "â•‘                    AKIJ RESOURCE - What Has Happened?                      â•‘\n",
    "â•‘                    Report Date: {analysis['date_range']['report_date']:^37} â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š OVERALL PERFORMANCE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Total Revenue:        à§³{analysis['overall_metrics']['total_revenue']:>15,.2f}\n",
    "Total Profit:         à§³{analysis['overall_metrics']['total_profit']:>15,.2f}\n",
    "Total Transactions:   {analysis['overall_metrics']['total_transactions']:>16,}\n",
    "Total Units Sold:     {analysis['overall_metrics']['total_quantity_sold']:>16,}\n",
    "Avg Transaction:      à§³{analysis['overall_metrics']['avg_transaction_value']:>15,.2f}\n",
    "Avg Profit Margin:    {analysis['overall_metrics']['avg_profit_margin']:>15.2f}%\n",
    "\n",
    "ğŸ“… TIME PERIOD (As of {analysis['date_range']['report_date']})\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Period: {analysis['date_range']['start']} to {analysis['date_range']['end']}\n",
    "Duration: {analysis['date_range']['days']} days (2 years)\n",
    "\n",
    "ğŸ† TOP PERFORMERS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Best Division:        {analysis['top_performers']['division']}\n",
    "Best Product:         {analysis['top_performers']['product']}\n",
    "Best Region:          {analysis['top_performers']['region']}\n",
    "Best Segment:         {analysis['top_performers']['segment']}\n",
    "Best Channel:         {analysis['top_performers']['channel']}\n",
    "\n",
    "ğŸ¢ REVENUE BY BUSINESS DIVISION\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for div, metrics in sorted(analysis['hierarchical_breakdown']['by_division'].items(), \n",
    "                                   key=lambda x: x[1]['revenue'], reverse=True):\n",
    "            pct = (metrics['revenue'] / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{div:.<40} à§³{metrics['revenue']:>12,.2f} ({pct:>5.1f}%) | Margin: {metrics['avg_margin']:.1f}%\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ“¦ TOP 15 PRODUCTS BY REVENUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for prod, rev in sorted(analysis['hierarchical_breakdown']['by_product_top15'].items(), \n",
    "                               key=lambda x: x[1], reverse=True):\n",
    "            pct = (rev / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{prod:.<50} à§³{rev:>12,.2f} ({pct:>4.1f}%)\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸŒ REVENUE BY REGION (Bangladesh Divisions)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for reg, metrics in sorted(analysis['hierarchical_breakdown']['by_region'].items(),\n",
    "                                   key=lambda x: x[1]['revenue'], reverse=True):\n",
    "            pct = (metrics['revenue'] / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{reg:.<25} à§³{metrics['revenue']:>12,.2f} ({pct:>5.1f}%) | Txns: {metrics['transactions']:,}\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ‘¥ REVENUE BY CUSTOMER SEGMENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for seg, rev in sorted(analysis['hierarchical_breakdown']['by_segment'].items(),\n",
    "                              key=lambda x: x[1], reverse=True):\n",
    "            pct = (rev / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{seg:.<35} à§³{rev:>12,.2f} ({pct:>5.1f}%)\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ›’ REVENUE BY SALES CHANNEL\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for chan, metrics in sorted(analysis['hierarchical_breakdown']['by_channel'].items(),\n",
    "                                   key=lambda x: x[1]['revenue'], reverse=True):\n",
    "            pct = (metrics['revenue'] / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{chan:.<30} à§³{metrics['revenue']:>12,.2f} ({pct:>5.1f}%) | Margin: {metrics['avg_margin']:.1f}%\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ“ˆ QUARTERLY PERFORMANCE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for q in sorted(analysis['temporal_trends']['quarterly_revenue'].keys()):\n",
    "            q_rev = analysis['temporal_trends']['quarterly_revenue'][q]\n",
    "            q_profit = analysis['temporal_trends']['quarterly_profit'][q]\n",
    "            q_margin = (q_profit / q_rev * 100) if q_rev > 0 else 0\n",
    "            summary += f\"Q{q}: Revenue à§³{q_rev:,.2f} | Profit à§³{q_profit:,.2f} | Margin {q_margin:.1f}%\\n\"\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run Descriptive Agent\n",
    "descriptive_agent = DescriptiveAgent(sales_data)\n",
    "descriptive_analysis = descriptive_agent.analyze()\n",
    "print(descriptive_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… SECTION 3 COMPLETE: Descriptive Analytics\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Š Key Insights (As of {datetime.now().strftime('%B %d, %Y')}):\")\n",
    "print(f\"   â€¢ {len(sales_data['product'].unique())} unique Akij products analyzed\")\n",
    "print(f\"   â€¢ {len(sales_data['business_division'].unique())} business divisions\")\n",
    "print(f\"   â€¢ Data period: {sales_data['date'].min().date()} to {sales_data['date'].max().date()}\")\n",
    "print(f\"   â€¢ Total Revenue: à§³{sales_data['revenue'].sum():,.2f}\")\n",
    "print(f\"   â€¢ Average Margin: {sales_data['profit_margin'].mean():.2f}%\")\n",
    "print(f\"   â€¢ Most recent transaction: {sales_data['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf1806",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 4: AGENT 2 - DIAGNOSTIC ANALYTICS (Why did it happen?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2fcb3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 2: DIAGNOSTIC ANALYTICS - Why did it happen?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f05cb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DiagnosticAgent:\n",
    "    \"\"\"\n",
    "    Diagnostic Agent performs root cause analysis to answer: \"Why did it happen?\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "    \n",
    "    def analyze(self) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive diagnostic analysis\"\"\"\n",
    "        \n",
    "        # Correlation analysis\n",
    "        numeric_cols = ['revenue', 'quantity', 'unit_price', 'cost', 'profit', 'profit_margin']\n",
    "        corr_matrix = self.data[numeric_cols].corr()\n",
    "        \n",
    "        key_correlations = {\n",
    "            \"revenue_quantity\": float(corr_matrix.loc['revenue', 'quantity']),\n",
    "            \"revenue_profit\": float(corr_matrix.loc['revenue', 'profit']),\n",
    "            \"price_margin\": float(corr_matrix.loc['unit_price', 'profit_margin'])\n",
    "        }\n",
    "        \n",
    "        # Identify underperforming divisions\n",
    "        overall_margin = self.data['profit_margin'].mean()\n",
    "        division_margins = self.data.groupby('business_division')['profit_margin'].mean()\n",
    "        underperformers = division_margins[division_margins < overall_margin].to_dict()\n",
    "        \n",
    "        # Channel efficiency analysis\n",
    "        channel_efficiency = self.data.groupby('sales_channel').agg({\n",
    "            'revenue': 'sum',\n",
    "            'profit': 'sum',\n",
    "            'profit_margin': 'mean',\n",
    "            'transaction_id': 'count'\n",
    "        }).round(2)\n",
    "        \n",
    "        channel_efficiency.columns = ['total_revenue', 'total_profit', 'avg_margin', 'transaction_count']\n",
    "        channel_efficiency['revenue_per_transaction'] = (\n",
    "            channel_efficiency['total_revenue'] / channel_efficiency['transaction_count']\n",
    "        ).round(2)\n",
    "        channel_efficiency_dict = channel_efficiency.to_dict('index')\n",
    "        \n",
    "        # Regional disparity analysis\n",
    "        regional_disparity_score = float(\n",
    "            self.data.groupby('region')['revenue'].sum().std() / \n",
    "            self.data.groupby('region')['revenue'].sum().mean()\n",
    "        )\n",
    "        \n",
    "        # Seasonal pattern detection\n",
    "        monthly_avg = self.data.groupby('month')['revenue'].mean()\n",
    "        peak_month = int(monthly_avg.idxmax())\n",
    "        low_month = int(monthly_avg.idxmin())\n",
    "        seasonality_strength = float((monthly_avg.max() - monthly_avg.min()) / monthly_avg.mean())\n",
    "        \n",
    "        # Generate insights\n",
    "        insights = self._generate_insights(\n",
    "            underperformers, channel_efficiency_dict, regional_disparity_score, \n",
    "            seasonality_strength, overall_margin\n",
    "        )\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Diagnostic Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"correlations\": key_correlations,\n",
    "            \"underperforming_divisions\": underperformers,\n",
    "            \"channel_efficiency\": channel_efficiency_dict,\n",
    "            \"regional_disparity\": {\n",
    "                \"disparity_score\": round(regional_disparity_score, 3),\n",
    "                \"interpretation\": \"High\" if regional_disparity_score > 0.3 else \"Moderate\" if regional_disparity_score > 0.15 else \"Low\"\n",
    "            },\n",
    "            \"seasonal_patterns\": {\n",
    "                \"peak_month\": peak_month,\n",
    "                \"low_month\": low_month,\n",
    "                \"seasonality_strength\": round(seasonality_strength, 3)\n",
    "            },\n",
    "            \"key_insights\": insights\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _generate_insights(self, underperformers, channel_eff, regional_disp, \n",
    "                          seasonality, overall_margin) -> List[str]:\n",
    "        \"\"\"Generate actionable insights from diagnostic analysis\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if underperformers:\n",
    "            insights.append(\n",
    "                f\"âš ï¸  {len(underperformers)} divisions below average margin ({overall_margin:.1f}%): \"\n",
    "                f\"{', '.join(underperformers.keys())}\"\n",
    "            )\n",
    "        \n",
    "        channel_margins = {k: v['avg_margin'] for k, v in channel_eff.items()}\n",
    "        worst_channel = min(channel_margins, key=channel_margins.get)\n",
    "        best_channel = max(channel_margins, key=channel_margins.get)\n",
    "        \n",
    "        insights.append(\n",
    "            f\"ğŸ“Š Channel performance gap: {best_channel} ({channel_margins[best_channel]:.1f}% margin) \"\n",
    "            f\"vs {worst_channel} ({channel_margins[worst_channel]:.1f}% margin)\"\n",
    "        )\n",
    "        \n",
    "        if regional_disp > 0.3:\n",
    "            insights.append(\n",
    "                f\"ğŸŒ High regional revenue disparity (score: {regional_disp:.2f}) - \"\n",
    "                \"indicates untapped potential in underperforming divisions\"\n",
    "            )\n",
    "        \n",
    "        if seasonality > 0.3:\n",
    "            insights.append(\n",
    "                f\"ğŸ“… Strong seasonal patterns (strength: {seasonality:.2f}) - \"\n",
    "                \"inventory and marketing should be adjusted seasonally\"\n",
    "            )\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    DIAGNOSTIC ANALYTICS REPORT                             â•‘\n",
    "â•‘                         Why Did It Happen?                                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ” KEY INSIGHTS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for insight in analysis['key_insights']:\n",
    "            summary += f\"\\n{insight}\\n\"\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_agent = DiagnosticAgent(sales_data)\n",
    "diagnostic_analysis = diagnostic_agent.analyze()\n",
    "print(diagnostic_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ab3b5",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 5: AGENT 3 - PREDICTIVE ANALYTICS (What is likely to happen?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22064e09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 3: PREDICTIVE ANALYTICS - What is likely to happen?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d7568",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class PredictiveAgent:\n",
    "    \"\"\"\n",
    "    Predictive Agent forecasts future trends\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "    \n",
    "    def analyze(self, forecast_days: int = 30) -> Dict[str, Any]:\n",
    "        \"\"\"Perform predictive analysis and forecasting\"\"\"\n",
    "        \n",
    "        # Calculate growth rate\n",
    "        recent_30_days = self.data.tail(300)['revenue'].mean()\n",
    "        previous_30_days = self.data.tail(600).head(300)['revenue'].mean()\n",
    "        growth_rate = ((recent_30_days - previous_30_days) / previous_30_days) if previous_30_days > 0 else 0\n",
    "        \n",
    "        # Forecast\n",
    "        last_week_avg = self.data.tail(70)['revenue'].mean()\n",
    "        forecast_daily_revenue = last_week_avg * (1 + growth_rate)\n",
    "        forecast_total_revenue = forecast_daily_revenue * forecast_days\n",
    "        \n",
    "        # Division-wise forecasts\n",
    "        division_forecasts = {}\n",
    "        for division in self.data['business_division'].unique():\n",
    "            div_data = self.data[self.data['business_division'] == division]\n",
    "            div_recent = div_data.tail(200)['revenue'].mean()\n",
    "            div_previous = div_data.head(200)['revenue'].mean()\n",
    "            \n",
    "            div_growth = ((div_recent - div_previous) / div_previous) if div_previous > 0 else 0\n",
    "            \n",
    "            division_forecasts[division] = {\n",
    "                \"growth_rate\": round(float(div_growth * 100), 2),\n",
    "                \"trend\": \"ğŸ“ˆ Growing\" if div_growth > 0.05 else \"ğŸ“‰ Declining\" if div_growth < -0.05 else \"â¡ï¸  Stable\"\n",
    "            }\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Predictive Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"forecast_period\": f\"{forecast_days} days\",\n",
    "            \"overall_forecast\": {\n",
    "                \"predicted_daily_revenue\": round(float(forecast_daily_revenue), 2),\n",
    "                \"predicted_total_revenue\": round(float(forecast_total_revenue), 2),\n",
    "                \"growth_rate_pct\": round(float(growth_rate * 100), 2)\n",
    "            },\n",
    "            \"division_forecasts\": division_forecasts\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    PREDICTIVE ANALYTICS REPORT                             â•‘\n",
    "â•‘                      What Is Likely to Happen?                             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ”® 30-DAY FORECAST\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Predicted Total Revenue: à§³{analysis['overall_forecast']['predicted_total_revenue']:,.2f}\n",
    "Growth Rate: {analysis['overall_forecast']['growth_rate_pct']:+.2f}%\n",
    "\n",
    "ğŸ“¦ DIVISION FORECASTS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for div, forecast in sorted(analysis['division_forecasts'].items(), \n",
    "                                    key=lambda x: x[1]['growth_rate'], reverse=True):\n",
    "            summary += f\"{div:.<40} {forecast['trend']} ({forecast['growth_rate']:+.1f}%)\\n\"\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_agent = PredictiveAgent(sales_data)\n",
    "predictive_analysis = predictive_agent.analyze()\n",
    "print(predictive_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcae258",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 6: AGENT 4 - PRESCRIPTIVE ANALYTICS (What should be done?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302bc2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 4: PRESCRIPTIVE ANALYTICS - What actions should be taken?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd243932",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class PrescriptiveAgent:\n",
    "    \"\"\"\n",
    "    Prescriptive Agent generates actionable recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, descriptive: Dict, diagnostic: Dict, predictive: Dict):\n",
    "        self.descriptive = descriptive\n",
    "        self.diagnostic = diagnostic\n",
    "        self.predictive = predictive\n",
    "    \n",
    "    def analyze(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive prescriptive recommendations\"\"\"\n",
    "        \n",
    "        immediate_actions = [\n",
    "            {\n",
    "                \"priority\": \"ğŸ”´ Critical\",\n",
    "                \"action\": \"Optimize underperforming divisions\",\n",
    "                \"timeline\": \"1-2 weeks\",\n",
    "                \"expected_impact\": \"5-10% margin improvement\"\n",
    "            },\n",
    "            {\n",
    "                \"priority\": \"ğŸŸ  High\",\n",
    "                \"action\": \"Expand high-growth divisions\",\n",
    "                \"timeline\": \"2-4 weeks\",\n",
    "                \"expected_impact\": \"15-20% revenue increase\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        strategic_initiatives = [\n",
    "            {\n",
    "                \"initiative\": \"Digital transformation of sales channels\",\n",
    "                \"timeline\": \"6-12 months\",\n",
    "                \"expected_impact\": \"25-30% efficiency gain\"\n",
    "            },\n",
    "            {\n",
    "                \"initiative\": \"Regional expansion strategy\",\n",
    "                \"timeline\": \"9-12 months\",\n",
    "                \"expected_impact\": \"20-25% market share increase\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Prescriptive Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"immediate_actions\": immediate_actions,\n",
    "            \"strategic_initiatives\": strategic_initiatives\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                   PRESCRIPTIVE ANALYTICS REPORT                            â•‘\n",
    "â•‘                    What Actions Should Be Taken?                           â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "âš¡ IMMEDIATE ACTIONS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for action in analysis['immediate_actions']:\n",
    "            summary += f\"\\n{action['priority']} {action['action']}\\n\"\n",
    "            summary += f\"Timeline: {action['timeline']} | Impact: {action['expected_impact']}\\n\"\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptive_agent = PrescriptiveAgent(descriptive_analysis, diagnostic_analysis, predictive_analysis)\n",
    "prescriptive_analysis = prescriptive_agent.analyze()\n",
    "print(prescriptive_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67ec22",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 7: N8N WORKFLOW EXPORT\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f9ad5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"N8N WORKFLOW INTEGRATION - GENERATING PAYLOAD\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b251a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "class N8NWorkflowGenerator:\n",
    "    \"\"\"Generate AI payload and auto-create n8n importable workflow\"\"\"\n",
    "\n",
    "    def __init__(self, desc_analysis: Dict, diag_analysis: Dict,\n",
    "                 pred_analysis: Dict, presc_analysis: Dict, raw_data: pd.DataFrame):\n",
    "        self.descriptive = desc_analysis\n",
    "        self.diagnostic = diag_analysis\n",
    "        self.predictive = pred_analysis\n",
    "        self.prescriptive = presc_analysis\n",
    "        self.raw_data = raw_data\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # STEP 1ï¸âƒ£ â€” Generate payload JSON\n",
    "    # ---------------------------------------------------------------------\n",
    "    def generate_workflow_payload(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate complete n8n-compatible AI payload\"\"\"\n",
    "\n",
    "        growth_rate = self.predictive['overall_forecast']['growth_rate_pct']\n",
    "        if growth_rate < -5:\n",
    "            priority = \"CRITICAL\"\n",
    "            alert_type = \"urgent\"\n",
    "        elif growth_rate < 0:\n",
    "            priority = \"HIGH\"\n",
    "            alert_type = \"warning\"\n",
    "        else:\n",
    "            priority = \"NORMAL\"\n",
    "            alert_type = \"info\"\n",
    "\n",
    "        payload = {\n",
    "            \"workflow_metadata\": {\n",
    "                \"workflow_name\": \"akij_sales_intelligence_multi_agent\",\n",
    "                \"workflow_version\": \"2.0\",\n",
    "                \"trigger_type\": \"scheduled_automated\",\n",
    "                \"organization\": \"Akij Resource\",\n",
    "                \"report_date\": datetime.now().strftime('%Y-%m-%d'),\n",
    "                \"report_time\": datetime.now().strftime('%H:%M:%S'),\n",
    "                \"generated_by\": \"Multi-Agent AI System\"\n",
    "            },\n",
    "            \"data_summary\": {\n",
    "                \"total_records\": len(self.raw_data),\n",
    "                \"date_range\": {\n",
    "                    \"start\": str(self.raw_data['date'].min().date()),\n",
    "                    \"end\": str(self.raw_data['date'].max().date())\n",
    "                },\n",
    "                \"total_revenue\": float(self.raw_data['revenue'].sum()),\n",
    "                \"total_profit\": float(self.raw_data['profit'].sum()),\n",
    "                \"avg_profit_margin\": float(self.raw_data['profit_margin'].mean()),\n",
    "                \"currency\": \"BDT (à§³)\"\n",
    "            },\n",
    "            \"analytics_results\": {\n",
    "                \"descriptive\": self.descriptive,\n",
    "                \"diagnostic\": self.diagnostic,\n",
    "                \"predictive\": self.predictive,\n",
    "                \"prescriptive\": self.prescriptive\n",
    "            },\n",
    "            \"alert_configuration\": {\n",
    "                \"priority\": priority,\n",
    "                \"alert_type\": alert_type,\n",
    "                \"notification_channels\": [\"email\", \"slack\", \"dashboard\"],\n",
    "                \"recipients\": [\n",
    "                    \"sales.director@akijresource.com\",\n",
    "                    \"cfo@akijresource.com\",\n",
    "                    \"analytics.team@akijresource.com\"\n",
    "                ]\n",
    "            },\n",
    "            \"actions_required\": [\n",
    "                {\n",
    "                    \"action_id\": f\"ACT{i+1:03d}\",\n",
    "                    \"priority\": action['priority'],\n",
    "                    \"description\": action['action'],\n",
    "                    \"timeline\": action['timeline'],\n",
    "                    \"expected_impact\": action['expected_impact'],\n",
    "                    \"status\": \"pending\",\n",
    "                    \"assigned_to\": \"sales_operations_team\"\n",
    "                }\n",
    "                for i, action in enumerate(self.prescriptive['immediate_actions'])\n",
    "            ],\n",
    "            \"webhook_config\": {\n",
    "                \"webhook_url\": \"https://mict4.app.n8n.cloud/home/webhook/akij-sales-intelligence\",\n",
    "                \"method\": \"POST\",\n",
    "                \"authentication\": \"bearer_token\",\n",
    "                \"retry_policy\": {\"max_retries\": 3, \"retry_interval\": 300}\n",
    "            },\n",
    "            \"integration_endpoints\": {\n",
    "                \"slack_webhook\": \"https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK\",\n",
    "                \"email_service\": \"smtp.akijresource.com\",\n",
    "                \"database_connection\": \"postgresql://analytics_db:5432/akij_sales\",\n",
    "                \"dashboard_api\": \"https://dashboard.akijresource.com/api/v1/update\"\n",
    "            },\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"webhook_ready\": True\n",
    "        }\n",
    "\n",
    "        return payload\n",
    "\n",
    "    def save_payload(self, filename: str = None) -> str:\n",
    "        \"\"\"Save payload JSON file\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"akij_payload_{datetime.now().strftime('%M%S')}.json\"\n",
    "        payload = self.generate_workflow_payload()\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "        return filename\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # STEP 2ï¸âƒ£ â€” Generate importable n8n workflow JSON\n",
    "    # ---------------------------------------------------------------------\n",
    "    def generate_n8n_workflow(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Convert payload into importable n8n workflow\"\"\"\n",
    "        p = payload\n",
    "\n",
    "        workflow = {\n",
    "            \"name\": f\"{p['workflow_metadata']['workflow_name']} (Auto Generated)\",\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"parameters\": {\"path\": \"akij-sales-intelligence\"},\n",
    "                    \"id\": \"Webhook_1\",\n",
    "                    \"name\": \"AI Report Webhook\",\n",
    "                    \"type\": \"n8n-nodes-base.webhook\",\n",
    "                    \"typeVersion\": 1,\n",
    "                    \"position\": [250, 300]\n",
    "                },\n",
    "                {\n",
    "                    \"parameters\": {\n",
    "                        \"functionCode\": (\n",
    "                            \"const payload = $json;\\n\"\n",
    "                            \"console.log('Payload received:', payload.workflow_metadata.workflow_name);\\n\"\n",
    "                            \"return [{ json: payload }];\"\n",
    "                        )\n",
    "                    },\n",
    "                    \"id\": \"Function_1\",\n",
    "                    \"name\": \"Process AI Report\",\n",
    "                    \"type\": \"n8n-nodes-base.function\",\n",
    "                    \"typeVersion\": 1,\n",
    "                    \"position\": [550, 300]\n",
    "                },\n",
    "                {\n",
    "                    \"parameters\": {\n",
    "                        \"url\": p[\"integration_endpoints\"][\"slack_webhook\"],\n",
    "                        \"method\": \"POST\",\n",
    "                        \"sendBody\": True,\n",
    "                        \"bodyParametersUi\": {\n",
    "                            \"parameter\": [\n",
    "                                {\n",
    "                                    \"name\": \"text\",\n",
    "                                    \"value\": f\"ğŸ“Š {p['workflow_metadata']['workflow_name']} report processed successfully!\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    \"id\": \"Slack_1\",\n",
    "                    \"name\": \"Notify Slack\",\n",
    "                    \"type\": \"n8n-nodes-base.httpRequest\",\n",
    "                    \"typeVersion\": 1,\n",
    "                    \"position\": [850, 300]\n",
    "                }\n",
    "            ],\n",
    "            \"connections\": {\n",
    "                \"AI Report Webhook\": {\"main\": [[{\"node\": \"Process AI Report\", \"type\": \"main\", \"index\": 0}]]},\n",
    "                \"Process AI Report\": {\"main\": [[{\"node\": \"Notify Slack\", \"type\": \"main\", \"index\": 0}]]}\n",
    "            },\n",
    "            \"active\": False,\n",
    "            \"settings\": {},\n",
    "            \"id\": str(int(datetime.now().timestamp()))\n",
    "        }\n",
    "\n",
    "        return workflow\n",
    "\n",
    "    def save_n8n_workflow(self, filename: str = None) -> str:\n",
    "        \"\"\"Save importable n8n workflow JSON\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"akij_n8n_workflow_{datetime.now().strftime('%M%S')}.json\"\n",
    "        payload = self.generate_workflow_payload()\n",
    "        workflow = self.generate_n8n_workflow(payload)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(workflow, f, indent=2)\n",
    "        return filename\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # STEP 3ï¸âƒ£ â€” Auto-generate both files\n",
    "    # ---------------------------------------------------------------------\n",
    "    def auto_generate(self) -> Dict[str, str]:\n",
    "        \"\"\"Generate both payload + workflow automatically\"\"\"\n",
    "        payload_file = self.save_payload()\n",
    "        workflow_file = self.save_n8n_workflow()\n",
    "        print(\"âœ… Payload saved:\", payload_file)\n",
    "        print(\"âœ… Importable workflow saved:\", workflow_file)\n",
    "        return {\"payload_file\": payload_file, \"workflow_file\": workflow_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7118425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n8n workflow files\n",
    "# Initialize the N8N workflow generator with all analyses and raw data\n",
    "n8n_generator = N8NWorkflowGenerator(\n",
    "    descriptive_analysis,\n",
    "    diagnostic_analysis,\n",
    "    predictive_analysis,\n",
    "    prescriptive_analysis,\n",
    "    sales_data\n",
    ")\n",
    "\n",
    "# Auto-generate both files\n",
    "n8n_generator.auto_generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fe631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n8n_payload = n8n_generator.generate_workflow_payload()\n",
    "#workflow_filename = n8n_generator.save_workflow()\n",
    "\n",
    "# Generate only AI payload JSON\n",
    "#payload_filename = n8n_generator.save_payload()\n",
    "\n",
    "# Generate only n8n importable workflow\n",
    "#workflow_filename = n8n_generator.save_n8n_workflow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "n8n_payload = n8n_generator.generate_workflow_payload()\n",
    "\n",
    "print(f\"\\nâœ… n8n Workflow Generated Successfully!\")\n",
    "print(f\"\\nğŸ“¦ Workflow Configuration:\")\n",
    "print(f\"   â€¢ Workflow Name: {n8n_payload['workflow_metadata']['workflow_name']}\")\n",
    "print(f\"   â€¢ Organization: {n8n_payload['workflow_metadata']['organization']}\")\n",
    "print(f\"   â€¢ Report Date: {n8n_payload['workflow_metadata']['report_date']}\")\n",
    "print(f\"   â€¢ Priority Level: {n8n_payload['alert_configuration']['priority']}\")\n",
    "print(f\"   â€¢ Alert Type: {n8n_payload['alert_configuration']['alert_type']}\")\n",
    "print(f\"   â€¢ Actions Required: {len(n8n_payload['actions_required'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ“„ Workflow Payload Saved:\")\n",
    "print(f\"   â€¢ Filename: {workflow_filename}\")\n",
    "print(f\"   â€¢ File Size: {len(json.dumps(n8n_payload, default=str))} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ”— Integration Endpoints Configured:\")\n",
    "for endpoint, url in n8n_payload['integration_endpoints'].items():\n",
    "    print(f\"   â€¢ {endpoint}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e993e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ“¨ Notification Channels:\")\n",
    "for channel in n8n_payload['alert_configuration']['notification_channels']:\n",
    "    print(f\"   â€¢ {channel.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d15957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ’¡ Webhook Configuration:\")\n",
    "print(f\"   â€¢ URL: {n8n_payload['webhook_config']['webhook_url']}\")\n",
    "print(f\"   â€¢ Method: {n8n_payload['webhook_config']['method']}\")\n",
    "print(f\"   â€¢ Max Retries: {n8n_payload['webhook_config']['retry_policy']['max_retries']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ“Š Sample Payload Preview (first 1000 chars):\")\n",
    "print(json.dumps(n8n_payload, indent=2, default=str)[:1000] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL SECTIONS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“ˆ Generated Deliverables:\")\n",
    "print(f\"   1. Sales Data: akij_sales_data_complete.csv\")\n",
    "print(f\"   2. n8n Workflow: {workflow_filename}\")\n",
    "print(f\"   3. Complete Analytics: All 4 agents executed\")\n",
    "print(f\"\\nğŸ¯ System Ready for Production Deployment!\")\n",
    "print(f\"\\nğŸ“ˆ To Launch Chatbot Interface & Dashboard: CLI Run\")\n",
    "print(f\"\\n streamlit run chatbot_ui.py\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "sales-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
