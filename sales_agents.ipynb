{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3120ef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================\n",
      "MULTI-AGENT SALES INTELLIGENCE SYSTEM - AKIJ RESOURCE\n",
      "AI Agent & Agentic Intelligence Specialist Project\n",
      "Submitted by: Abdul Matin\n",
      "Organization: Akij Resource\n",
      "Date: November 2025\n",
      "=============================================================================\n",
      "\n",
      "This Jupyter Notebook demonstrates:\n",
      "1. Four Analytical Frameworks (Descriptive, Diagnostic, Predictive, Prescriptive)\n",
      "2. Multi-Agent Architecture using LangChain\n",
      "3. Agentic Intelligence with autonomous reasoning\n",
      "4. n8n Integration capability\n",
      "5. Conversational AI interface\n",
      "\n",
      "Currency: Bangladeshi Taka (à§³)\n",
      "Regions: Bangladesh Divisions (Dhaka, Chittagong, Rangpur, Khulna, Mymensingh, Rajshahi, Sylhet, Barisal)\n",
      "Products: Complete Akij Resource Product Portfolio (80+ Products)\n",
      "\n",
      "Run all cells sequentially to see the complete system in action.\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The docstring content, assigned to a variable\n",
    "docstring_content = \"\"\"\n",
    "=============================================================================\n",
    "MULTI-AGENT SALES INTELLIGENCE SYSTEM - AKIJ RESOURCE\n",
    "AI Agent & Agentic Intelligence Specialist Project\n",
    "Submitted by: Abdul Matin\n",
    "Organization: Akij Resource\n",
    "Date: November 2025\n",
    "=============================================================================\n",
    "\n",
    "This Jupyter Notebook demonstrates:\n",
    "1. Four Analytical Frameworks (Descriptive, Diagnostic, Predictive, Prescriptive)\n",
    "2. Multi-Agent Architecture using LangChain\n",
    "3. Agentic Intelligence with autonomous reasoning\n",
    "4. n8n Integration capability\n",
    "5. Conversational AI interface\n",
    "\n",
    "Currency: Bangladeshi Taka (à§³)\n",
    "Regions: Bangladesh Divisions (Dhaka, Chittagong, Rangpur, Khulna, Mymensingh, Rajshahi, Sylhet, Barisal)\n",
    "Products: Complete Akij Resource Product Portfolio (80+ Products)\n",
    "\n",
    "Run all cells sequentially to see the complete system in action.\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Printing the content directly will show it with proper line breaks\n",
    "print(docstring_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701b72a",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 1: SETUP & DEPENDENCIES\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4272edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INSTALLING DEPENDENCIES...\n",
      "================================================================================\n",
      "âœ… INSTALLING DEPENDENCIES Successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"INSTALLING DEPENDENCIES...\")\n",
    "print(\"=\"*80)\n",
    "# Uncomment to install in Google Colab or local Jupyter\n",
    "#!pip install -q langchain langchain-openai pandas numpy plotly python-dotenv\n",
    "print(\"âœ… INSTALLING DEPENDENCIES Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66f45e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# ğŸ“¦ Dependency Imports\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Core data libraries\n",
    "import pandas as pd      # Data manipulation and analysis\n",
    "import numpy as np       # Numerical operations and array handling\n",
    "# Date & time utilities\n",
    "from datetime import datetime, timedelta   # Timestamp generation, date calculationsi\n",
    "# Type hinting (improves code readability and structure)\n",
    "from typing import Dict, List, Any, Tuple  # Used for function signatures and return types\n",
    "# JSON utilities\n",
    "import json              # Reading/writing structured JSON data\n",
    "# Warning control\n",
    "import warnings          # Helps hide unnecessary runtime warnings\n",
    "warnings.filterwarnings('ignore')   # Suppresses warnings for clean notebook output\n",
    "# Status message\n",
    "print(\"âœ… Dependencies loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedbfb1",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 2: SALES DATA GENERATION - AKIJ PRODUCTS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc7cb9c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING HIERARCHICAL SALES DATA - AKIJ RESOURCE\n",
      "================================================================================\n",
      "âœ… SalesDataGenerator Loaded Successfully.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# GENERATING HIERARCHICAL SALES DATA - AKIJ RESOURCE\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING HIERARCHICAL SALES DATA - AKIJ RESOURCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "class SalesDataGenerator:\n",
    "    \"\"\"\n",
    "    Generate realistic sales dataset with complete Akij Resource product portfolio.\n",
    "    This class simulates:\n",
    "      - Full product mapping\n",
    "      - Weighted division-wise sampling\n",
    "      - Region/segment/channel distributions\n",
    "      - Revenue, cost, profit modeling\n",
    "      - Seasonal adjustments\n",
    "      - Time-based features\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_sales_data(num_records: int = 4000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate synthetic sales data with Akij product categories organized by business divisions.\n",
    "        No changes were made to the internal logic. Only comments + print statements added.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"[1] Initializing random seed and preparing product portfolios...\")\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Complete Akij Resource Product Portfolio organized by Business Division\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"    - Loading product lists for all business divisions...\")\n",
    "        akij_products = {\n",
    "            'Beverages & Food': [\n",
    "                'Mojo', 'Frutika (Juice)', 'Speed (Energy Drink)', 'Clemon', 'Twing', 'Lemu', \n",
    "                'Royal Tiger', 'Spa Drinking Water', 'Yummy Lassi', 'Farm Fresh Milk (UHT)', \n",
    "                'Farm Fresh Ghee', 'Akij Daily Spices', 'Akij Daily Edible Oil', 'Akij Tea',\n",
    "                'Aafi Snacks (Chanachur)', \"O'Potato Chips\", 'Happy Times Jam', \n",
    "                \"Bakeman's Biscuits\", 'Funtastic Chocolate', 'Akij Flour (Atta)', \n",
    "                'Akij Maida', 'Akij Suji', 'Akij Muri (Puffed Rice)', 'Essential Chinigura Rice',\n",
    "                'Akij Bakers Bread', 'Akij Bakers Bun', 'Akij Bakers Cake'\n",
    "            ],\n",
    "            'Building & Construction': [\n",
    "                'Akij Cement (PCC/CEM-I)', 'Akij Ceramics Tiles (Wall/Floor/Stair)', \n",
    "                'Kathena Tiles', 'Sierra Tiles', 'Espacio Tiles', 'Rosa Sanitaryware',\n",
    "                'Akij Board (Particle Board/MDF)', 'Akij Door (Laminated)', 'Akij Door (Solid)',\n",
    "                'Akij Pipes & Fittings', 'Akij Buildtech', 'Akij Rebar (TMT)'\n",
    "            ],\n",
    "            'FMCG & Household': [\n",
    "                'Max Wash Detergent Powder', 'Dish Master (Liquid)', 'Dish Master (Bar)',\n",
    "                'Fantastik Air Freshener', 'H&H Hand Wash', 'Mum Mum Baby Diaper',\n",
    "                'Akij Daily Home Care Products', 'Akij Plastics Furniture', \n",
    "                'Akij Plastics Household Items'\n",
    "            ],\n",
    "            'Industrial & Other': [\n",
    "                'Akij Jute Yarn', 'Akij Jute Sacks', 'Akij Textile Woven Fabric', \n",
    "                'Akij Textile Denim', 'Akij Tableware (Porcelain)', \n",
    "                'Akij Motors Electric Bike', 'Akij Motors Three-Wheeler',\n",
    "                'AKIJ Power Light LED Bulb', 'AKIJ Fan (Ceiling Fan)', \n",
    "                'AKIJ AURA Switch', 'AKIJ DELIGHT Socket', 'Akij Electrical Cables',\n",
    "                'AKIJ Circuit Breaker (MCB)', 'Akij BIAX Films (BOPET)', \n",
    "                'Akij BIAX Films (CPP)', 'Akij Printing & Packaging',\n",
    "                'Akij Pharma Medicine', 'Akij Footwear', 'BONN Bicycle', \"B'FIRE Bicycle\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Flatten product list and create mapping\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[2] Creating product â†’ business division mapping...\")\n",
    "        all_products = []\n",
    "        product_to_division = {}\n",
    "\n",
    "        for division, products in akij_products.items():\n",
    "            all_products.extend(products)\n",
    "            for product in products:\n",
    "                product_to_division[product] = division\n",
    "\n",
    "        total_products = len(all_products)\n",
    "        print(f\"    - Total products loaded: {total_products}\")\n",
    "        print(f\"    - Total business divisions: {len(akij_products)}\")\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Weighted distribution for products\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[3] Computing weighted distribution for product sampling...\")\n",
    "        division_weights = {\n",
    "            'Beverages & Food': 0.40,\n",
    "            'Building & Construction': 0.30,\n",
    "            'FMCG & Household': 0.20,\n",
    "            'Industrial & Other': 0.10\n",
    "        }\n",
    "\n",
    "        product_weights = []\n",
    "        for product in all_products:\n",
    "            division = product_to_division[product]\n",
    "            division_weight = division_weights[division]\n",
    "            num_products_in_division = len(akij_products[division])\n",
    "            product_weight = division_weight / num_products_in_division\n",
    "            product_weights.append(product_weight)\n",
    "\n",
    "        product_weights = np.array(product_weights)\n",
    "        product_weights = product_weights / product_weights.sum()\n",
    "        print(\"    - Product weights normalized.\")\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Segments, Regions, Channels\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[4] Defining customer segments, regions, and sales channels...\")\n",
    "        print(\"    - Customer segmentation groups loaded.\")\n",
    "        print(\"    - Geographic regions initialized.\")\n",
    "        print(\"    - Sales channel distribution configured.\")\n",
    "        \n",
    "        segments = ['Enterprise', 'SMB', 'Individual', 'Government', 'Retail Distributor', 'Wholesaler']\n",
    "        regions = ['Dhaka', 'Chittagong', 'Rangpur', 'Khulna', 'Mymensingh', 'Rajshahi', 'Sylhet', 'Barisal']\n",
    "        channels = ['Online', 'Retail Store', 'Wholesale', 'Direct Sales', 'Distributor Network']\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Date range generation\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[5] Generating 2-year date range...\")\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=730)\n",
    "        total_days = (end_date - start_date).days + 1\n",
    "        dates = [start_date + timedelta(days=x) for x in range(total_days)]\n",
    "        print(f\"    - Date range: {start_date.date()} to {end_date.date()}\")\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Create base DataFrame\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[6] Generating base dataset with random sampling...\")\n",
    "        print(\"    - Assigning transaction IDs.\")\n",
    "        print(\"    - Sampling dates, products, segments, regions, and channels.\")\n",
    "        print(\"    - Base structure of the dataset created.\")\n",
    "\n",
    "        data = {\n",
    "            'transaction_id': [f'AKJ{str(i).zfill(7)}' for i in range(1, num_records + 1)],\n",
    "            'date': np.random.choice(dates, num_records),\n",
    "            'product': np.random.choice(all_products, num_records, p=product_weights),\n",
    "            'customer_segment': np.random.choice(segments, num_records, p=[0.20, 0.25, 0.25, 0.08, 0.12, 0.10]),\n",
    "            'region': np.random.choice(regions, num_records, p=[0.28, 0.20, 0.10, 0.12, 0.08, 0.10, 0.07, 0.05]),\n",
    "            'sales_channel': np.random.choice(channels, num_records, p=[0.25, 0.25, 0.20, 0.15, 0.15]),\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Add business division\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[7] Mapping each product to its corresponding business division...\")\n",
    "        print(\"    - Every product has been linked to its division category.\")\n",
    "        print(\"    - 'business_division' column added to dataset.\")\n",
    "        df['business_division'] = df['product'].map(product_to_division)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Revenue modeling\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[8] Computing revenue based on division-specific patterns...\")\n",
    "        base_revenue = np.random.uniform(500, 50000, num_records)\n",
    "\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'Building & Construction',\n",
    "            base_revenue * np.random.uniform(2.0, 3.5, num_records),\n",
    "            base_revenue\n",
    "        )\n",
    "\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'Industrial & Other',\n",
    "            df['revenue'] * np.random.uniform(1.5, 2.5, num_records),\n",
    "            df['revenue']\n",
    "        )\n",
    "\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'Beverages & Food',\n",
    "            df['revenue'] * np.random.uniform(0.6, 1.2, num_records),\n",
    "            df['revenue']\n",
    "        )\n",
    "\n",
    "        df['revenue'] = np.where(\n",
    "            df['business_division'] == 'FMCG & Household',\n",
    "            df['revenue'] * np.random.uniform(0.5, 1.0, num_records),\n",
    "            df['revenue']\n",
    "        )\n",
    "\n",
    "        print(\"    - Revenue adjusted for segment and region multipliers.\")\n",
    "        df['revenue'] = df['revenue'] * np.where(df['customer_segment'] == 'Enterprise', 1.5, 1.0)\n",
    "        df['revenue'] = df['revenue'] * np.where(df['customer_segment'] == 'Government', 1.4, 1.0)\n",
    "        df['revenue'] = df['revenue'] * np.where(df['customer_segment'] == 'Wholesaler', 1.3, 1.0)\n",
    "        df['revenue'] = df['revenue'] * np.where(df['region'].isin(['Dhaka', 'Chittagong']), 1.3, 1.0)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Quantity modeling\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[9] Generating quantity values for each product...\")\n",
    "        df['quantity'] = np.where(\n",
    "            df['business_division'].isin(['Beverages & Food', 'FMCG & Household']),\n",
    "            np.random.randint(100, 1000, num_records),\n",
    "            np.random.randint(1, 100, num_records)\n",
    "        )\n",
    "\n",
    "        df['quantity'] = np.where(\n",
    "            df['business_division'] == 'Building & Construction',\n",
    "            np.random.randint(10, 200, num_records),\n",
    "            df['quantity']\n",
    "        )\n",
    "\n",
    "        df['unit_price'] = df['revenue'] / df['quantity']\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Cost modeling\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[10] Computing cost, profit, and profit margin...\")\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'Beverages & Food',\n",
    "            df['revenue'] * np.random.uniform(0.65, 0.75, num_records),\n",
    "            df['revenue'] * np.random.uniform(0.50, 0.70, num_records)\n",
    "        )\n",
    "\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'Building & Construction',\n",
    "            df['revenue'] * np.random.uniform(0.60, 0.70, num_records),\n",
    "            df['cost']\n",
    "        )\n",
    "\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'FMCG & Household',\n",
    "            df['revenue'] * np.random.uniform(0.70, 0.80, num_records),\n",
    "            df['cost']\n",
    "        )\n",
    "\n",
    "        df['cost'] = np.where(\n",
    "            df['business_division'] == 'Industrial & Other',\n",
    "            df['revenue'] * np.random.uniform(0.55, 0.65, num_records),\n",
    "            df['cost']\n",
    "        )\n",
    "\n",
    "        df['profit'] = df['revenue'] - df['cost']\n",
    "        df['profit_margin'] = (df['profit'] / df['revenue']) * 100\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Time dimensions\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[11] Adding time-based attributes...\")\n",
    "        df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "        df['quarter'] = pd.to_datetime(df['date']).dt.quarter\n",
    "        df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "        df['month_name'] = pd.to_datetime(df['date']).dt.strftime('%B')\n",
    "        df['week'] = pd.to_datetime(df['date']).dt.isocalendar().week\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Seasonal adjustments\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[12] Applying seasonal adjustments to revenue...\")\n",
    "        df.loc[(df['business_division'] == 'Beverages & Food') & \n",
    "               (df['product'].str.contains('Mojo|Frutika|Speed|Clemon|Twing|Lemu|Spa', case=False, na=False)) & \n",
    "               (df['month'].isin([4, 5, 6, 7])), 'revenue'] *= 1.4\n",
    "\n",
    "        df.loc[(df['business_division'] == 'Building & Construction') & \n",
    "               (df['month'].isin([11, 12, 1, 2, 3])), 'revenue'] *= 1.3\n",
    "\n",
    "        df.loc[(df['business_division'] == 'FMCG & Household') & \n",
    "               (df['month'].isin([3, 4, 8, 9])), 'revenue'] *= 1.2\n",
    "\n",
    "        df.loc[df['sales_channel'].isin(['Online', 'Direct Sales']), 'profit_margin'] *= 1.08\n",
    "\n",
    "        # Recalculate profit after seasonal adjustments\n",
    "        df['profit'] = df['revenue'] - df['cost']\n",
    "        df['profit_margin'] = (df['profit'] / df['revenue']) * 100\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Final sorting\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"[13] Finalizing dataset and sorting by date...\")\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        print(\"âœ… Sales dataset successfully generated.\\n\\n\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "print(\"âœ… SalesDataGenerator Loaded Successfully.\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "089d670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Generating sales data...\n",
      "[1] Initializing random seed and preparing product portfolios...\n",
      "    - Loading product lists for all business divisions...\n",
      "[2] Creating product â†’ business division mapping...\n",
      "    - Total products loaded: 68\n",
      "    - Total business divisions: 4\n",
      "[3] Computing weighted distribution for product sampling...\n",
      "    - Product weights normalized.\n",
      "[4] Defining customer segments, regions, and sales channels...\n",
      "    - Customer segmentation groups loaded.\n",
      "    - Geographic regions initialized.\n",
      "    - Sales channel distribution configured.\n",
      "[5] Generating 2-year date range...\n",
      "    - Date range: 2023-11-21 to 2025-11-20\n",
      "[6] Generating base dataset with random sampling...\n",
      "    - Assigning transaction IDs.\n",
      "    - Sampling dates, products, segments, regions, and channels.\n",
      "    - Base structure of the dataset created.\n",
      "[7] Mapping each product to its corresponding business division...\n",
      "    - Every product has been linked to its division category.\n",
      "    - 'business_division' column added to dataset.\n",
      "[8] Computing revenue based on division-specific patterns...\n",
      "    - Revenue adjusted for segment and region multipliers.\n",
      "[9] Generating quantity values for each product...\n",
      "[10] Computing cost, profit, and profit margin...\n",
      "[11] Adding time-based attributes...\n",
      "[12] Applying seasonal adjustments to revenue...\n",
      "[13] Finalizing dataset and sorting by date...\n",
      "âœ… Sales dataset successfully generated.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "print(\"ğŸ”„ Generating sales data...\")\n",
    "sales_data = SalesDataGenerator.generate_sales_data(num_records=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a34eeeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Generated 4,000 sales transactions\n",
      "ğŸ“… Date Range: 2023-11-21 to 2025-11-20\n",
      "ğŸ“† Report Date: November 20, 2025 (Today)\n",
      "â±ï¸  Data Coverage: 2 years (724 days)\n",
      "ğŸ’° Total Revenue: à§³224,504,337.23\n",
      "ğŸ’µ Total Profit: à§³86,097,591.68\n",
      "ğŸ“Š Average Margin: 34.94%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nâœ… Generated {len(sales_data):,} sales transactions\")\n",
    "print(f\"ğŸ“… Date Range: {sales_data['date'].min().date()} to {sales_data['date'].max().date()}\")\n",
    "print(f\"ğŸ“† Report Date: {datetime.now().strftime('%B %d, %Y')} (Today)\")\n",
    "print(f\"â±ï¸  Data Coverage: 2 years ({sales_data['date'].nunique()} days)\")\n",
    "print(f\"ğŸ’° Total Revenue: à§³{sales_data['revenue'].sum():,.2f}\")\n",
    "print(f\"ğŸ’µ Total Profit: à§³{sales_data['profit'].sum():,.2f}\")\n",
    "print(f\"ğŸ“Š Average Margin: {sales_data['profit_margin'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31e98502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¢ BUSINESS DIVISIONS:\n",
      "ğŸ“Š Division Summary (Generated Successfully):\n",
      "                        Total Revenue (à§³)  Transactions\n",
      "business_division                                      \n",
      "Beverages & Food               51,933,944          1631\n",
      "Building & Construction       123,523,080          1198\n",
      "FMCG & Household               22,454,263           782\n",
      "Industrial & Other             26,593,048           389\n"
     ]
    }
   ],
   "source": [
    "# Display section title for business divisions\n",
    "print(f\"\\nğŸ¢ BUSINESS DIVISIONS:\")\n",
    "\n",
    "# Group the sales data by business division and calculate:\n",
    "# - Total revenue (sum)\n",
    "# - Number of transactions (count)\n",
    "division_summary = sales_data.groupby('business_division').agg({\n",
    "    'revenue': 'sum',            # Sum of revenue per division\n",
    "    'transaction_id': 'count'    # Number of transactions per division\n",
    "}).round(2)                      # Round results to 2 decimal places\n",
    "\n",
    "# Rename the columns for clarity\n",
    "division_summary.columns = ['Total Revenue (à§³)', 'Transactions']\n",
    "division_summary['Total Revenue (à§³)'] = division_summary['Total Revenue (à§³)'].apply(lambda x: f\"{int(x):,}\")\n",
    "\n",
    "\n",
    "# Print summary table\n",
    "print(\"ğŸ“Š Division Summary (Generated Successfully):\")\n",
    "print(division_summary.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "49f99347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ TOP 15 PRODUCTS BY REVENUE:\n",
      "ğŸ“Š Top product revenue summary generated successfully:\n",
      "   1. Akij Door (Laminated)............................. à§³12,639,221.07\n",
      "   2. Akij Cement (PCC/CEM-I)........................... à§³11,310,474.13\n",
      "   3. Rosa Sanitaryware................................. à§³11,129,481.06\n",
      "   4. Akij Buildtech.................................... à§³10,771,265.36\n",
      "   5. Akij Ceramics Tiles (Wall/Floor/Stair)............ à§³10,727,750.07\n",
      "   6. Akij Board (Particle Board/MDF)................... à§³10,395,155.90\n",
      "   7. Espacio Tiles..................................... à§³10,252,504.77\n",
      "   8. Akij Rebar (TMT).................................. à§³10,171,022.05\n",
      "   9. Akij Pipes & Fittings............................. à§³9,778,305.78\n",
      "  10. Kathena Tiles..................................... à§³9,464,809.78\n",
      "  11. Akij Door (Solid)................................. à§³8,588,060.34\n",
      "  12. Sierra Tiles...................................... à§³8,295,030.66\n",
      "  13. H&H Hand Wash..................................... à§³2,943,050.62\n",
      "  14. Dish Master (Bar)................................. à§³2,911,986.18\n",
      "  15. Lemu.............................................. à§³2,746,073.40\n"
     ]
    }
   ],
   "source": [
    "# Display section title for top products by revenue\n",
    "print(f\"\\nğŸ“¦ TOP 15 PRODUCTS BY REVENUE:\")\n",
    "\n",
    "# Group by product, sum revenue, sort descending, and take top 15\n",
    "top_products = sales_data.groupby('product')['revenue'].sum().sort_values(ascending=False).head(15)\n",
    "\n",
    "# Extra print to confirm summary creation\n",
    "print(\"ğŸ“Š Top product revenue summary generated successfully:\")\n",
    "\n",
    "# Loop through top 15 products and print formatted output\n",
    "for i, (product, revenue) in enumerate(top_products.items(), 1):\n",
    "    # Print rank, product name padded with dots, and formatted revenue\n",
    "    print(f\"  {i:2d}. {product:.<50} à§³{revenue:>12,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "48c67c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ REVENUE BY REGION:\n",
      "ğŸ“Š Regional revenue summary generated successfully:\n",
      "  Dhaka.................... à§³74,095,481.17 ( 33.0%)\n",
      "  Chittagong............... à§³51,961,761.54 ( 23.1%)\n",
      "  Khulna................... à§³22,094,619.72 (  9.8%)\n",
      "  Rajshahi................. à§³21,165,826.45 (  9.4%)\n",
      "  Rangpur.................. à§³18,449,899.44 (  8.2%)\n",
      "  Mymensingh............... à§³13,300,171.82 (  5.9%)\n",
      "  Sylhet................... à§³13,094,761.69 (  5.8%)\n",
      "  Barisal.................. à§³10,341,815.40 (  4.6%)\n"
     ]
    }
   ],
   "source": [
    "# Display section title for regional revenue\n",
    "print(f\"\\nğŸŒ REVENUE BY REGION:\")\n",
    "# Group data by region and calculate total revenue (sorted descending)\n",
    "region_summary = sales_data.groupby('region')['revenue'].sum().sort_values(ascending=False)\n",
    "# Extra confirmation print\n",
    "print(\"ğŸ“Š Regional revenue summary generated successfully:\")\n",
    "# Loop through each region and print revenue + percentage of total\n",
    "for region, revenue in region_summary.items():\n",
    "    pct = (revenue / sales_data['revenue'].sum()) * 100  # % share of total revenue\n",
    "    print(f\"  {region:.<25} à§³{revenue:>12,.2f} ({pct:>5.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e4063fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Sample Data Preview:\n",
      "ğŸ“„ Showing the first 10 rows (index starting from 1):\n",
      "   transaction_id                       date                          product  \\\n",
      "1      AKJ0000756 2023-11-21 23:22:21.943633  Akij Board (Particle Board/MDF)   \n",
      "2      AKJ0001978 2023-11-21 23:22:21.943633          Fantastik Air Freshener   \n",
      "3      AKJ0000980 2023-11-21 23:22:21.943633                Akij Bakers Bread   \n",
      "4      AKJ0003251 2023-11-21 23:22:21.943633                         Akij Tea   \n",
      "5      AKJ0002035 2023-11-21 23:22:21.943633                      Yummy Lassi   \n",
      "6      AKJ0003052 2023-11-21 23:22:21.943633                    H&H Hand Wash   \n",
      "7      AKJ0001138 2023-11-21 23:22:21.943633              Funtastic Chocolate   \n",
      "8      AKJ0000649 2023-11-21 23:22:21.943633            Akij Door (Laminated)   \n",
      "9      AKJ0003557 2023-11-21 23:22:21.943633                 Akij Rebar (TMT)   \n",
      "10     AKJ0000069 2023-11-22 23:22:21.943633                           Clemon   \n",
      "\n",
      "          business_division      region       revenue  profit_margin  \n",
      "1   Building & Construction  Chittagong  51244.529766      53.148395  \n",
      "2          FMCG & Household       Dhaka   6907.384777      26.334873  \n",
      "3          Beverages & Food     Rangpur  37932.277630      28.366588  \n",
      "4          Beverages & Food  Chittagong  47293.656895      30.252594  \n",
      "5          Beverages & Food      Sylhet  49705.692994      34.992725  \n",
      "6          FMCG & Household       Dhaka  51421.329633      29.216284  \n",
      "7          Beverages & Food       Dhaka  49325.342423      28.298773  \n",
      "8   Building & Construction  Chittagong  58600.392462      49.238878  \n",
      "9   Building & Construction      Khulna  34712.221413      48.813529  \n",
      "10         Beverages & Food  Chittagong  46360.823542      30.048977  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ“Š Sample Data Preview:\")\n",
    "\n",
    "# Explain what is happening\n",
    "print(\"ğŸ“„ Showing the first 10 rows (index starting from 1):\")\n",
    "\n",
    "# Select preview rows\n",
    "sales_preview = sales_data[['transaction_id', 'date', 'product', 'business_division',\n",
    "                            'region', 'revenue', 'profit_margin']].head(10)\n",
    "\n",
    "# Make index start from 1 instead of 0\n",
    "sales_preview.index = sales_preview.index + 1\n",
    "\n",
    "# Display final result\n",
    "print(sales_preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f43f4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ The dataset has been exported to CSV format and stored locally.\n",
      "\n",
      "âœ… Data saved to 'akij_sales_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the full sales dataset to a CSV file (without index column)\n",
    "sales_data.to_csv('akij_sales_data.csv', index=False)\n",
    "\n",
    "# Extra print explaining what just happened\n",
    "print(\"ğŸ’¾ The dataset has been exported to CSV format and stored locally.\")\n",
    "\n",
    "# Original confirmation message\n",
    "print(\"\\nâœ… Data saved to 'akij_sales_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2861b4a",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 3: AGENT 1 - DESCRIPTIVE ANALYTICS (What has happened?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "556ccc56",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGENT 1: DESCRIPTIVE ANALYTICS - What has happened?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 1: DESCRIPTIVE ANALYTICS - What has happened?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "867cbfb4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… AGENT 1 - DescriptiveAgent loaded successfully! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DescriptiveAgent:\n",
    "    \"\"\"\n",
    "    Descriptive Agent analyzes historical data to answer: \"What has happened?\"\n",
    "    - Summarizes past performance\n",
    "    - Identifies patterns and trends\n",
    "    - Provides comprehensive data overview\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        print(\"ğŸ”§ Initializing Descriptive Agent...\")\n",
    "        self.data = data\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])  # Convert to datetime\n",
    "        print(f\"âœ“ Loaded {len(self.data)} transactions\\n\")\n",
    "    \n",
    "    def analyze(self) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive descriptive analysis\"\"\"\n",
    "        print(\"ğŸ“Š Analyzing...\")\n",
    "        \n",
    "        # Overall metrics\n",
    "        print(\"  â€¢ Business metrics\", end=\"... \")\n",
    "        total_revenue = float(self.data['revenue'].sum())\n",
    "        total_profit = float(self.data['profit'].sum())\n",
    "        total_transactions = len(self.data)\n",
    "        avg_transaction_value = float(self.data['revenue'].mean())\n",
    "        avg_profit_margin = float(self.data['profit_margin'].mean())\n",
    "        total_quantity = int(self.data['quantity'].sum())\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Time-based analysis\n",
    "        print(\"  â€¢ Time period\", end=\"... \")\n",
    "        date_range = {\n",
    "            \"start\": str(self.data['date'].min().date()),\n",
    "            \"end\": str(self.data['date'].max().date()),\n",
    "            \"days\": (self.data['date'].max() - self.data['date'].min()).days,\n",
    "            \"report_date\": datetime.now().strftime('%B %d, %Y')\n",
    "        }\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Business Division analysis\n",
    "        print(\"  â€¢ Divisions\", end=\"... \")\n",
    "        division_revenue = self.data.groupby('business_division')['revenue'].sum().sort_values(ascending=False)\n",
    "        division_profit = self.data.groupby('business_division')['profit'].sum().sort_values(ascending=False)\n",
    "        division_margin = self.data.groupby('business_division')['profit_margin'].mean().sort_values(ascending=False)\n",
    "        top_division = division_revenue.idxmax()\n",
    "        division_breakdown = {\n",
    "            div: {\n",
    "                'revenue': round(float(division_revenue[div]), 2),\n",
    "                'profit': round(float(division_profit[div]), 2),\n",
    "                'avg_margin': round(float(division_margin[div]), 2)\n",
    "            }\n",
    "            for div in division_revenue.index\n",
    "        }\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Product analysis (Top 15)\n",
    "        print(\"  â€¢ Products\", end=\"... \")\n",
    "        product_revenue = self.data.groupby('product')['revenue'].sum().sort_values(ascending=False).head(15)\n",
    "        top_product = product_revenue.idxmax()\n",
    "        product_breakdown = product_revenue.to_dict()\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Regional analysis\n",
    "        print(\"  â€¢ Regions\", end=\"... \")\n",
    "        region_revenue = self.data.groupby('region')['revenue'].sum().sort_values(ascending=False)\n",
    "        region_transactions = self.data.groupby('region')['transaction_id'].count()\n",
    "        top_region = region_revenue.idxmax()\n",
    "        region_breakdown = {\n",
    "            reg: {\n",
    "                'revenue': round(float(region_revenue[reg]), 2),\n",
    "                'transactions': int(region_transactions[reg])\n",
    "            }\n",
    "            for reg in region_revenue.index\n",
    "        }\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Segment analysis\n",
    "        print(\"  â€¢ Segments\", end=\"... \")\n",
    "        segment_revenue = self.data.groupby('customer_segment')['revenue'].sum().sort_values(ascending=False)\n",
    "        top_segment = segment_revenue.idxmax()\n",
    "        segment_breakdown = segment_revenue.to_dict()\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Channel analysis\n",
    "        print(\"  â€¢ Channels\", end=\"... \")\n",
    "        channel_revenue = self.data.groupby('sales_channel')['revenue'].sum().sort_values(ascending=False)\n",
    "        channel_margin = self.data.groupby('sales_channel')['profit_margin'].mean()\n",
    "        top_channel = channel_revenue.idxmax()\n",
    "        channel_breakdown = {\n",
    "            chan: {\n",
    "                'revenue': round(float(channel_revenue[chan]), 2),\n",
    "                'avg_margin': round(float(channel_margin[chan]), 2)\n",
    "            }\n",
    "            for chan in channel_revenue.index\n",
    "        }\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Monthly trends\n",
    "        print(\"  â€¢ Monthly trends\", end=\"... \")\n",
    "        monthly_revenue = self.data.groupby('month')['revenue'].sum().to_dict()\n",
    "        monthly_volume = self.data.groupby('month')['transaction_id'].count().to_dict()\n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        # Quarterly performance\n",
    "        print(\"  â€¢ Quarterly data\", end=\"... \")\n",
    "        quarterly_revenue = self.data.groupby('quarter')['revenue'].sum().to_dict()\n",
    "        quarterly_profit = self.data.groupby('quarter')['profit'].sum().to_dict()\n",
    "        print(\"âœ“\\n\")\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Descriptive Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"overall_metrics\": {\n",
    "                \"total_revenue\": round(total_revenue, 2),\n",
    "                \"total_profit\": round(total_profit, 2),\n",
    "                \"total_transactions\": total_transactions,\n",
    "                \"total_quantity_sold\": total_quantity,\n",
    "                \"avg_transaction_value\": round(avg_transaction_value, 2),\n",
    "                \"avg_profit_margin\": round(avg_profit_margin, 2)\n",
    "            },\n",
    "            \"date_range\": date_range,\n",
    "            \"top_performers\": {\n",
    "                \"division\": top_division,\n",
    "                \"product\": top_product,\n",
    "                \"region\": top_region,\n",
    "                \"segment\": top_segment,\n",
    "                \"channel\": top_channel\n",
    "            },\n",
    "            \"hierarchical_breakdown\": {\n",
    "                \"by_division\": division_breakdown,\n",
    "                \"by_product_top15\": {k: round(v, 2) for k, v in product_breakdown.items()},\n",
    "                \"by_region\": region_breakdown,\n",
    "                \"by_segment\": {k: round(v, 2) for k, v in segment_breakdown.items()},\n",
    "                \"by_channel\": channel_breakdown\n",
    "            },\n",
    "            \"temporal_trends\": {\n",
    "                \"monthly_revenue\": {k: round(v, 2) for k, v in monthly_revenue.items()},\n",
    "                \"monthly_volume\": monthly_volume,\n",
    "                \"quarterly_revenue\": {k: round(v, 2) for k, v in quarterly_revenue.items()},\n",
    "                \"quarterly_profit\": {k: round(v, 2) for k, v in quarterly_profit.items()}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        print(\"ğŸ“ Generating report...\\n\")\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    DESCRIPTIVE ANALYTICS REPORT                            â•‘\n",
    "â•‘                    AKIJ RESOURCE - What Has Happened?                      â•‘\n",
    "â•‘                    Report Date: {analysis['date_range']['report_date']:^37} â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š OVERALL PERFORMANCE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Total Revenue:        à§³{analysis['overall_metrics']['total_revenue']:>15,.2f}\n",
    "Total Profit:         à§³{analysis['overall_metrics']['total_profit']:>15,.2f}\n",
    "Total Transactions:   {analysis['overall_metrics']['total_transactions']:>16,}\n",
    "Total Units Sold:     {analysis['overall_metrics']['total_quantity_sold']:>16,}\n",
    "Avg Transaction:      à§³{analysis['overall_metrics']['avg_transaction_value']:>15,.2f}\n",
    "Avg Profit Margin:    {analysis['overall_metrics']['avg_profit_margin']:>15.2f}%\n",
    "\n",
    "ğŸ“… TIME PERIOD (As of {analysis['date_range']['report_date']})\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Period: {analysis['date_range']['start']} to {analysis['date_range']['end']}\n",
    "Duration: {analysis['date_range']['days']} days (2 years)\n",
    "\n",
    "ğŸ† TOP PERFORMERS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Best Division:        {analysis['top_performers']['division']}\n",
    "Best Product:         {analysis['top_performers']['product']}\n",
    "Best Region:          {analysis['top_performers']['region']}\n",
    "Best Segment:         {analysis['top_performers']['segment']}\n",
    "Best Channel:         {analysis['top_performers']['channel']}\n",
    "\n",
    "ğŸ¢ REVENUE BY BUSINESS DIVISION\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for div, metrics in sorted(analysis['hierarchical_breakdown']['by_division'].items(), \n",
    "                                   key=lambda x: x[1]['revenue'], reverse=True):\n",
    "            pct = (metrics['revenue'] / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{div:.<40} à§³{metrics['revenue']:>12,.2f} ({pct:>5.1f}%) | Margin: {metrics['avg_margin']:.1f}%\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ“¦ TOP 15 PRODUCTS BY REVENUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for prod, rev in sorted(analysis['hierarchical_breakdown']['by_product_top15'].items(), \n",
    "                               key=lambda x: x[1], reverse=True):\n",
    "            pct = (rev / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{prod:.<50} à§³{rev:>12,.2f} ({pct:>4.1f}%)\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸŒ REVENUE BY REGION (Bangladesh Divisions)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for reg, metrics in sorted(analysis['hierarchical_breakdown']['by_region'].items(),\n",
    "                                   key=lambda x: x[1]['revenue'], reverse=True):\n",
    "            pct = (metrics['revenue'] / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{reg:.<25} à§³{metrics['revenue']:>12,.2f} ({pct:>5.1f}%) | Txns: {metrics['transactions']:,}\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ‘¥ REVENUE BY CUSTOMER SEGMENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for seg, rev in sorted(analysis['hierarchical_breakdown']['by_segment'].items(),\n",
    "                              key=lambda x: x[1], reverse=True):\n",
    "            pct = (rev / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{seg:.<35} à§³{rev:>12,.2f} ({pct:>5.1f}%)\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ›’ REVENUE BY SALES CHANNEL\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for chan, metrics in sorted(analysis['hierarchical_breakdown']['by_channel'].items(),\n",
    "                                   key=lambda x: x[1]['revenue'], reverse=True):\n",
    "            pct = (metrics['revenue'] / analysis['overall_metrics']['total_revenue']) * 100\n",
    "            summary += f\"{chan:.<30} à§³{metrics['revenue']:>12,.2f} ({pct:>5.1f}%) | Margin: {metrics['avg_margin']:.1f}%\\n\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "ğŸ“ˆ QUARTERLY PERFORMANCE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for q in sorted(analysis['temporal_trends']['quarterly_revenue'].keys()):\n",
    "            q_rev = analysis['temporal_trends']['quarterly_revenue'][q]\n",
    "            q_profit = analysis['temporal_trends']['quarterly_profit'][q]\n",
    "            q_margin = (q_profit / q_rev * 100) if q_rev > 0 else 0\n",
    "            summary += f\"Q{q}: Revenue à§³{q_rev:,.2f} | Profit à§³{q_profit:,.2f} | Margin {q_margin:.1f}%\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "print(\"\\nâœ… AGENT 1 - DescriptiveAgent loaded successfully! \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e025baf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING DESCRIPTIVE ANALYTICS AGENT\n",
      "================================================================================\n",
      "\n",
      "ğŸ”§ Initializing Descriptive Agent...\n",
      "âœ“ Loaded 4000 transactions\n",
      "\n",
      "ğŸ“Š Analyzing...\n",
      "  â€¢ Business metrics... âœ“\n",
      "  â€¢ Time period... âœ“\n",
      "  â€¢ Divisions... âœ“\n",
      "  â€¢ Products... âœ“\n",
      "  â€¢ Regions... âœ“\n",
      "  â€¢ Segments... âœ“\n",
      "  â€¢ Channels... âœ“\n",
      "  â€¢ Monthly trends... âœ“\n",
      "  â€¢ Quarterly data... âœ“\n",
      "\n",
      "ğŸ“ Generating report...\n",
      "\n",
      "ğŸ“Š Analyzing...\n",
      "  â€¢ Business metrics... âœ“\n",
      "  â€¢ Time period... âœ“\n",
      "  â€¢ Divisions... âœ“\n",
      "  â€¢ Products... âœ“\n",
      "  â€¢ Regions... âœ“\n",
      "  â€¢ Segments... âœ“\n",
      "  â€¢ Channels... âœ“\n",
      "  â€¢ Monthly trends... âœ“\n",
      "  â€¢ Quarterly data... âœ“\n",
      "\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    DESCRIPTIVE ANALYTICS REPORT                            â•‘\n",
      "â•‘                    AKIJ RESOURCE - What Has Happened?                      â•‘\n",
      "â•‘                    Report Date:           November 20, 2025           â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“Š OVERALL PERFORMANCE\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Total Revenue:        à§³ 224,504,337.23\n",
      "Total Profit:         à§³  86,097,591.68\n",
      "Total Transactions:              4,000\n",
      "Total Units Sold:            1,451,602\n",
      "Avg Transaction:      à§³      56,126.08\n",
      "Avg Profit Margin:              34.94%\n",
      "\n",
      "ğŸ“… TIME PERIOD (As of November 20, 2025)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Period: 2023-11-21 to 2025-11-20\n",
      "Duration: 730 days (2 years)\n",
      "\n",
      "ğŸ† TOP PERFORMERS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Best Division:        Building & Construction\n",
      "Best Product:         Akij Door (Laminated)\n",
      "Best Region:          Dhaka\n",
      "Best Segment:         Enterprise\n",
      "Best Channel:         Retail Store\n",
      "\n",
      "ğŸ¢ REVENUE BY BUSINESS DIVISION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Building & Construction................. à§³123,523,080.98 ( 55.0%) | Margin: 41.4%\n",
      "Beverages & Food........................ à§³51,933,944.68 ( 23.1%) | Margin: 31.9%\n",
      "Industrial & Other...................... à§³26,593,048.16 ( 11.8%) | Margin: 39.9%\n",
      "FMCG & Household........................ à§³22,454,263.41 ( 10.0%) | Margin: 29.0%\n",
      "\n",
      "ğŸ“¦ TOP 15 PRODUCTS BY REVENUE\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Akij Door (Laminated)............................. à§³12,639,221.07 ( 5.6%)\n",
      "Akij Cement (PCC/CEM-I)........................... à§³11,310,474.13 ( 5.0%)\n",
      "Rosa Sanitaryware................................. à§³11,129,481.06 ( 5.0%)\n",
      "Akij Buildtech.................................... à§³10,771,265.36 ( 4.8%)\n",
      "Akij Ceramics Tiles (Wall/Floor/Stair)............ à§³10,727,750.07 ( 4.8%)\n",
      "Akij Board (Particle Board/MDF)................... à§³10,395,155.90 ( 4.6%)\n",
      "Espacio Tiles..................................... à§³10,252,504.77 ( 4.6%)\n",
      "Akij Rebar (TMT).................................. à§³10,171,022.05 ( 4.5%)\n",
      "Akij Pipes & Fittings............................. à§³9,778,305.78 ( 4.4%)\n",
      "Kathena Tiles..................................... à§³9,464,809.78 ( 4.2%)\n",
      "Akij Door (Solid)................................. à§³8,588,060.34 ( 3.8%)\n",
      "Sierra Tiles...................................... à§³8,295,030.66 ( 3.7%)\n",
      "H&H Hand Wash..................................... à§³2,943,050.62 ( 1.3%)\n",
      "Dish Master (Bar)................................. à§³2,911,986.18 ( 1.3%)\n",
      "Lemu.............................................. à§³2,746,073.40 ( 1.2%)\n",
      "\n",
      "ğŸŒ REVENUE BY REGION (Bangladesh Divisions)\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Dhaka.................... à§³74,095,481.17 ( 33.0%) | Txns: 1,133\n",
      "Chittagong............... à§³51,961,761.54 ( 23.1%) | Txns: 814\n",
      "Khulna................... à§³22,094,619.72 (  9.8%) | Txns: 463\n",
      "Rajshahi................. à§³21,165,826.45 (  9.4%) | Txns: 417\n",
      "Rangpur.................. à§³18,449,899.44 (  8.2%) | Txns: 376\n",
      "Mymensingh............... à§³13,300,171.82 (  5.9%) | Txns: 297\n",
      "Sylhet................... à§³13,094,761.69 (  5.8%) | Txns: 283\n",
      "Barisal.................. à§³10,341,815.40 (  4.6%) | Txns: 217\n",
      "\n",
      "ğŸ‘¥ REVENUE BY CUSTOMER SEGMENT\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Enterprise......................... à§³54,428,980.73 ( 24.2%)\n",
      "SMB................................ à§³54,140,371.27 ( 24.1%)\n",
      "Individual......................... à§³49,405,951.14 ( 22.0%)\n",
      "Wholesaler......................... à§³23,397,733.61 ( 10.4%)\n",
      "Retail Distributor................. à§³21,904,534.34 (  9.8%)\n",
      "Government......................... à§³21,226,766.14 (  9.5%)\n",
      "\n",
      "ğŸ›’ REVENUE BY SALES CHANNEL\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Retail Store.................. à§³56,248,521.77 ( 25.1%) | Margin: 35.2%\n",
      "Online........................ à§³54,560,402.23 ( 24.3%) | Margin: 35.2%\n",
      "Wholesale..................... à§³46,398,808.12 ( 20.7%) | Margin: 34.9%\n",
      "Direct Sales.................. à§³36,007,043.86 ( 16.0%) | Margin: 34.9%\n",
      "Distributor Network........... à§³31,289,561.24 ( 13.9%) | Margin: 34.3%\n",
      "\n",
      "ğŸ“ˆ QUARTERLY PERFORMANCE\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Q1: Revenue à§³56,010,586.79 | Profit à§³23,969,438.46 | Margin 42.8%\n",
      "Q2: Revenue à§³53,259,163.78 | Profit à§³19,086,262.54 | Margin 35.8%\n",
      "Q3: Revenue à§³57,438,057.67 | Profit à§³19,987,995.31 | Margin 34.8%\n",
      "Q4: Revenue à§³57,796,528.99 | Profit à§³23,053,895.38 | Margin 39.9%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run Descriptive Agent\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING DESCRIPTIVE ANALYTICS AGENT\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "descriptive_agent = DescriptiveAgent(sales_data)\n",
    "descriptive_analysis = descriptive_agent.analyze()\n",
    "print(descriptive_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "613a04d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… SECTION 3 COMPLETE: Descriptive Analytics\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Key Insights (As of November 20, 2025):\n",
      "   â€¢ 68 unique Akij products analyzed\n",
      "   â€¢ 4 business divisions\n",
      "   â€¢ Data period: 2023-11-21 to 2025-11-20\n",
      "   â€¢ Total Revenue: à§³224,504,337.23\n",
      "   â€¢ Average Margin: 34.94%\n",
      "   â€¢ Most recent transaction: 2025-11-20\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… SECTION 3 COMPLETE: Descriptive Analytics\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Š Key Insights (As of {datetime.now().strftime('%B %d, %Y')}):\")\n",
    "print(f\"   â€¢ {len(sales_data['product'].unique())} unique Akij products analyzed\")\n",
    "print(f\"   â€¢ {len(sales_data['business_division'].unique())} business divisions\")\n",
    "print(f\"   â€¢ Data period: {sales_data['date'].min().date()} to {sales_data['date'].max().date()}\")\n",
    "print(f\"   â€¢ Total Revenue: à§³{sales_data['revenue'].sum():,.2f}\")\n",
    "print(f\"   â€¢ Average Margin: {sales_data['profit_margin'].mean():.2f}%\")\n",
    "print(f\"   â€¢ Most recent transaction: {sales_data['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf1806",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 4: AGENT 2 - DIAGNOSTIC ANALYTICS (Why did it happen?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b0d2fcb3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGENT 2: DIAGNOSTIC ANALYTICS - Why did it happen?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 2: DIAGNOSTIC ANALYTICS - Why did it happen?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "317f05cb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… AGENT 2- Diagnostic Agent loaded successfully! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DiagnosticAgent:\n",
    "    \"\"\"\n",
    "    Diagnostic Agent performs root cause analysis to answer: \"Why did it happen?\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "    \n",
    "    def analyze(self) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive diagnostic analysis\"\"\"\n",
    "        \n",
    "        # Correlation analysis\n",
    "        numeric_cols = ['revenue', 'quantity', 'unit_price', 'cost', 'profit', 'profit_margin']\n",
    "        corr_matrix = self.data[numeric_cols].corr()\n",
    "        \n",
    "        key_correlations = {\n",
    "            \"revenue_quantity\": float(corr_matrix.loc['revenue', 'quantity']),\n",
    "            \"revenue_profit\": float(corr_matrix.loc['revenue', 'profit']),\n",
    "            \"price_margin\": float(corr_matrix.loc['unit_price', 'profit_margin'])\n",
    "        }\n",
    "        \n",
    "        # Identify underperforming divisions\n",
    "        overall_margin = self.data['profit_margin'].mean()\n",
    "        division_margins = self.data.groupby('business_division')['profit_margin'].mean()\n",
    "        underperformers = division_margins[division_margins < overall_margin].to_dict()\n",
    "        \n",
    "        # Channel efficiency analysis\n",
    "        channel_efficiency = self.data.groupby('sales_channel').agg({\n",
    "            'revenue': 'sum',\n",
    "            'profit': 'sum',\n",
    "            'profit_margin': 'mean',\n",
    "            'transaction_id': 'count'\n",
    "        }).round(2)\n",
    "        \n",
    "        channel_efficiency.columns = ['total_revenue', 'total_profit', 'avg_margin', 'transaction_count']\n",
    "        channel_efficiency['revenue_per_transaction'] = (\n",
    "            channel_efficiency['total_revenue'] / channel_efficiency['transaction_count']\n",
    "        ).round(2)\n",
    "        channel_efficiency_dict = channel_efficiency.to_dict('index')\n",
    "        \n",
    "        # Regional disparity analysis\n",
    "        regional_disparity_score = float(\n",
    "            self.data.groupby('region')['revenue'].sum().std() / \n",
    "            self.data.groupby('region')['revenue'].sum().mean()\n",
    "        )\n",
    "        \n",
    "        # Seasonal pattern detection\n",
    "        monthly_avg = self.data.groupby('month')['revenue'].mean()\n",
    "        peak_month = int(monthly_avg.idxmax())\n",
    "        low_month = int(monthly_avg.idxmin())\n",
    "        seasonality_strength = float((monthly_avg.max() - monthly_avg.min()) / monthly_avg.mean())\n",
    "        \n",
    "        # Generate insights\n",
    "        insights = self._generate_insights(\n",
    "            underperformers, channel_efficiency_dict, regional_disparity_score, \n",
    "            seasonality_strength, overall_margin\n",
    "        )\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Diagnostic Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"correlations\": key_correlations,\n",
    "            \"underperforming_divisions\": underperformers,\n",
    "            \"channel_efficiency\": channel_efficiency_dict,\n",
    "            \"regional_disparity\": {\n",
    "                \"disparity_score\": round(regional_disparity_score, 3),\n",
    "                \"interpretation\": \"High\" if regional_disparity_score > 0.3 else \"Moderate\" if regional_disparity_score > 0.15 else \"Low\"\n",
    "            },\n",
    "            \"seasonal_patterns\": {\n",
    "                \"peak_month\": peak_month,\n",
    "                \"low_month\": low_month,\n",
    "                \"seasonality_strength\": round(seasonality_strength, 3)\n",
    "            },\n",
    "            \"key_insights\": insights\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _generate_insights(self, underperformers, channel_eff, regional_disp, \n",
    "                          seasonality, overall_margin) -> List[str]:\n",
    "        \"\"\"Generate actionable insights from diagnostic analysis\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if underperformers:\n",
    "            insights.append(\n",
    "                f\"âš ï¸  {len(underperformers)} divisions below average margin ({overall_margin:.1f}%): \"\n",
    "                f\"{', '.join(underperformers.keys())}\"\n",
    "            )\n",
    "        \n",
    "        channel_margins = {k: v['avg_margin'] for k, v in channel_eff.items()}\n",
    "        worst_channel = min(channel_margins, key=channel_margins.get)\n",
    "        best_channel = max(channel_margins, key=channel_margins.get)\n",
    "        \n",
    "        insights.append(\n",
    "            f\"ğŸ“Š Channel performance gap: {best_channel} ({channel_margins[best_channel]:.1f}% margin) \"\n",
    "            f\"vs {worst_channel} ({channel_margins[worst_channel]:.1f}% margin)\"\n",
    "        )\n",
    "        \n",
    "        if regional_disp > 0.3:\n",
    "            insights.append(\n",
    "                f\"ğŸŒ High regional revenue disparity (score: {regional_disp:.2f}) - \"\n",
    "                \"indicates untapped potential in underperforming divisions\"\n",
    "            )\n",
    "        \n",
    "        if seasonality > 0.3:\n",
    "            insights.append(\n",
    "                f\"ğŸ“… Strong seasonal patterns (strength: {seasonality:.2f}) - \"\n",
    "                \"inventory and marketing should be adjusted seasonally\"\n",
    "            )\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    DIAGNOSTIC ANALYTICS REPORT                             â•‘\n",
    "â•‘                         Why Did It Happen?                                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ” KEY INSIGHTS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for insight in analysis['key_insights']:\n",
    "            summary += f\"\\n{insight}\\n\"\n",
    "        \n",
    "        return summary\n",
    "print(\"\\nâœ… AGENT 2- Diagnostic Agent loaded successfully! \\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ccb3d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    DIAGNOSTIC ANALYTICS REPORT                             â•‘\n",
      "â•‘                         Why Did It Happen?                                 â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ” KEY INSIGHTS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "âš ï¸  2 divisions below average margin (34.9%): Beverages & Food, FMCG & Household\n",
      "\n",
      "ğŸ“Š Channel performance gap: Retail Store (35.2% margin) vs Distributor Network (34.3% margin)\n",
      "\n",
      "ğŸŒ High regional revenue disparity (score: 0.81) - indicates untapped potential in underperforming divisions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'sales_data' is a pre-loaded dataset (e.g., pandas DataFrame) \n",
    "# required for the DiagnosticAgent to function.\n",
    "# 1. Initialization: Create an instance of the DiagnosticAgent.\n",
    "# This object is instantiated with the data it needs to analyze.\n",
    "diagnostic_agent = DiagnosticAgent(sales_data)\n",
    "# 2. Execution: Run the core analysis logic defined within the agent.\n",
    "# This step performs calculations, identifies trends, or detects anomalies.\n",
    "# The result is stored in 'diagnostic_analysis' for potential later use.\n",
    "diagnostic_analysis = diagnostic_agent.analyze()\n",
    "# 3. Reporting: Generate and display a concise summary of the findings.\n",
    "# This calls a method to format the results of the analysis into a human-readable string.\n",
    "print(diagnostic_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ab3b5",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 5: AGENT 3 - PREDICTIVE ANALYTICS (What is likely to happen?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "22064e09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGENT 3: PREDICTIVE ANALYTICS - What is likely to happen?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 3: PREDICTIVE ANALYTICS - What is likely to happen?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca1d7568",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… AGENT 3- Predictive Agent loaded successfully! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PredictiveAgent:\n",
    "    \"\"\"\n",
    "    Predictive Agent forecasts future trends\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "    \n",
    "    def analyze(self, forecast_days: int = 30) -> Dict[str, Any]:\n",
    "        \"\"\"Perform predictive analysis and forecasting\"\"\"\n",
    "        \n",
    "        # Calculate growth rate\n",
    "        recent_30_days = self.data.tail(300)['revenue'].mean()\n",
    "        previous_30_days = self.data.tail(600).head(300)['revenue'].mean()\n",
    "        growth_rate = ((recent_30_days - previous_30_days) / previous_30_days) if previous_30_days > 0 else 0\n",
    "        \n",
    "        # Forecast\n",
    "        last_week_avg = self.data.tail(70)['revenue'].mean()\n",
    "        forecast_daily_revenue = last_week_avg * (1 + growth_rate)\n",
    "        forecast_total_revenue = forecast_daily_revenue * forecast_days\n",
    "        \n",
    "        # Division-wise forecasts\n",
    "        division_forecasts = {}\n",
    "        for division in self.data['business_division'].unique():\n",
    "            div_data = self.data[self.data['business_division'] == division]\n",
    "            div_recent = div_data.tail(200)['revenue'].mean()\n",
    "            div_previous = div_data.head(200)['revenue'].mean()\n",
    "            \n",
    "            div_growth = ((div_recent - div_previous) / div_previous) if div_previous > 0 else 0\n",
    "            \n",
    "            division_forecasts[division] = {\n",
    "                \"growth_rate\": round(float(div_growth * 100), 2),\n",
    "                \"trend\": \"ğŸ“ˆ Growing\" if div_growth > 0.05 else \"ğŸ“‰ Declining\" if div_growth < -0.05 else \"â¡ï¸  Stable\"\n",
    "            }\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Predictive Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"forecast_period\": f\"{forecast_days} days\",\n",
    "            \"overall_forecast\": {\n",
    "                \"predicted_daily_revenue\": round(float(forecast_daily_revenue), 2),\n",
    "                \"predicted_total_revenue\": round(float(forecast_total_revenue), 2),\n",
    "                \"growth_rate_pct\": round(float(growth_rate * 100), 2)\n",
    "            },\n",
    "            \"division_forecasts\": division_forecasts\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    PREDICTIVE ANALYTICS REPORT                             â•‘\n",
    "â•‘                      What Is Likely to Happen?                             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ”® 30-DAY FORECAST\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Predicted Total Revenue: à§³{analysis['overall_forecast']['predicted_total_revenue']:,.2f}\n",
    "Growth Rate: {analysis['overall_forecast']['growth_rate_pct']:+.2f}%\n",
    "\n",
    "ğŸ“¦ DIVISION FORECASTS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for div, forecast in sorted(analysis['division_forecasts'].items(), \n",
    "                                    key=lambda x: x[1]['growth_rate'], reverse=True):\n",
    "            summary += f\"{div:.<40} {forecast['trend']} ({forecast['growth_rate']:+.1f}%)\\n\"\n",
    "        \n",
    "        return summary\n",
    "print(\"\\nâœ… AGENT 3- Predictive Agent loaded successfully! \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c882d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    PREDICTIVE ANALYTICS REPORT                             â•‘\n",
      "â•‘                      What Is Likely to Happen?                             â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ”® 30-DAY FORECAST\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "Predicted Total Revenue: à§³1,862,017.31\n",
      "Growth Rate: -3.80%\n",
      "\n",
      "ğŸ“¦ DIVISION FORECASTS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "FMCG & Household........................ ğŸ“ˆ Growing (+14.8%)\n",
      "Beverages & Food........................ â¡ï¸  Stable (-0.6%)\n",
      "Industrial & Other...................... ğŸ“‰ Declining (-10.7%)\n",
      "Building & Construction................. ğŸ“‰ Declining (-19.2%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'sales_data' is a pre-loaded pandas DataFrame (or similar structure)\n",
    "# that contains the necessary 'date', 'revenue', and 'business_division' columns.\n",
    "\n",
    "# 1. Initialization: Create an instance of the PredictiveAgent.\n",
    "# The agent is instantiated with the historical sales data it needs to forecast trends.\n",
    "predictive_agent = PredictiveAgent(sales_data)\n",
    "\n",
    "# 2. Execution: Run the core predictive analysis and forecasting logic.\n",
    "# This calculates growth rates and forecasts revenue for the next 30 days.\n",
    "# The result is stored in 'predictive_analysis'.\n",
    "predictive_analysis = predictive_agent.analyze()\n",
    "\n",
    "# 3. Reporting: Generate and display a structured, human-readable summary of the forecasts.\n",
    "print(predictive_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcae258",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 6: AGENT 4 - PRESCRIPTIVE ANALYTICS (What should be done?)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7302bc2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGENT 4: PRESCRIPTIVE ANALYTICS - What actions should be taken?\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT 4: PRESCRIPTIVE ANALYTICS - What actions should be taken?\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dd243932",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… AGENT 4- Prescriptive Agent loaded successfully! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PrescriptiveAgent:\n",
    "    \"\"\"\n",
    "    Prescriptive Agent generates actionable recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, descriptive: Dict, diagnostic: Dict, predictive: Dict):\n",
    "        self.descriptive = descriptive\n",
    "        self.diagnostic = diagnostic\n",
    "        self.predictive = predictive\n",
    "    \n",
    "    def analyze(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive prescriptive recommendations\"\"\"\n",
    "        \n",
    "        immediate_actions = [\n",
    "            {\n",
    "                \"priority\": \"ğŸ”´ Critical\",\n",
    "                \"action\": \"Optimize underperforming divisions\",\n",
    "                \"timeline\": \"1-2 weeks\",\n",
    "                \"expected_impact\": \"5-10% margin improvement\"\n",
    "            },\n",
    "            {\n",
    "                \"priority\": \"ğŸŸ  High\",\n",
    "                \"action\": \"Expand high-growth divisions\",\n",
    "                \"timeline\": \"2-4 weeks\",\n",
    "                \"expected_impact\": \"15-20% revenue increase\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        strategic_initiatives = [\n",
    "            {\n",
    "                \"initiative\": \"Digital transformation of sales channels\",\n",
    "                \"timeline\": \"6-12 months\",\n",
    "                \"expected_impact\": \"25-30% efficiency gain\"\n",
    "            },\n",
    "            {\n",
    "                \"initiative\": \"Regional expansion strategy\",\n",
    "                \"timeline\": \"9-12 months\",\n",
    "                \"expected_impact\": \"20-25% market share increase\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        analysis = {\n",
    "            \"agent_name\": \"Prescriptive Analytics Agent - Akij Resource\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"immediate_actions\": immediate_actions,\n",
    "            \"strategic_initiatives\": strategic_initiatives\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_summary(self) -> str:\n",
    "        \"\"\"Generate human-readable summary\"\"\"\n",
    "        analysis = self.analyze()\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                   PRESCRIPTIVE ANALYTICS REPORT                            â•‘\n",
    "â•‘                    What Actions Should Be Taken?                           â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "âš¡ IMMEDIATE ACTIONS\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "        for action in analysis['immediate_actions']:\n",
    "            summary += f\"\\n{action['priority']} {action['action']}\\n\"\n",
    "            summary += f\"Timeline: {action['timeline']} | Impact: {action['expected_impact']}\\n\"\n",
    "        \n",
    "        return summary\n",
    "print(\"\\nâœ… AGENT 4- Prescriptive Agent loaded successfully! \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fad0f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                   PRESCRIPTIVE ANALYTICS REPORT                            â•‘\n",
      "â•‘                    What Actions Should Be Taken?                           â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "âš¡ IMMEDIATE ACTIONS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ”´ Critical Optimize underperforming divisions\n",
      "Timeline: 1-2 weeks | Impact: 5-10% margin improvement\n",
      "\n",
      "ğŸŸ  High Expand high-growth divisions\n",
      "Timeline: 2-4 weeks | Impact: 15-20% revenue increase\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the following analysis results are pre-calculated and available:\n",
    "# - 'descriptive_analysis' (What happened?)\n",
    "# - 'diagnostic_analysis' (Why did it happen?)\n",
    "# - 'predictive_analysis' (What will happen?)\n",
    "\n",
    "# 1. Initialization: Create an instance of the PrescriptiveAgent.\n",
    "# The agent requires the findings from all previous stages to formulate recommendations.\n",
    "prescriptive_agent = PrescriptiveAgent(descriptive_analysis, diagnostic_analysis, predictive_analysis)\n",
    "\n",
    "# 2. Execution: Run the core prescriptive analysis logic.\n",
    "# This step identifies specific, actionable steps (e.g., \"Invest in X,\" \"Reduce Y\")\n",
    "# based on the combined data from the three preceding analyses.\n",
    "prescriptive_analysis = prescriptive_agent.analyze()\n",
    "\n",
    "# 3. Reporting: Generate and display a structured summary of the recommended actions.\n",
    "print(prescriptive_agent.generate_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67ec22",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "SECTION 7: N8N WORKFLOW EXPORT\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7c4f9ad5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "N8N WORKFLOW INTEGRATION - GENERATING PAYLOAD\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"N8N WORKFLOW INTEGRATION - GENERATING PAYLOAD\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37b251a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… AGENT 5/OPS- n8n Workflow Builder Agent loaded successfully! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class N8NWorkflowGenerator:\n",
    "    \"\"\"Generate AI payload and auto-create n8n importable workflow\"\"\"\n",
    "\n",
    "    def __init__(self, desc_analysis: Dict, diag_analysis: Dict,\n",
    "                 pred_analysis: Dict, presc_analysis: Dict, raw_data: pd.DataFrame):\n",
    "        self.descriptive = desc_analysis\n",
    "        self.diagnostic = diag_analysis\n",
    "        self.predictive = pred_analysis\n",
    "        self.prescriptive = presc_analysis\n",
    "        self.raw_data = raw_data\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # STEP 1ï¸âƒ£ â€” Generate payload JSON\n",
    "    # ---------------------------------------------------------------------\n",
    "    def generate_workflow_payload(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate complete n8n-compatible AI payload\"\"\"\n",
    "\n",
    "        growth_rate = self.predictive['overall_forecast']['growth_rate_pct']\n",
    "        if growth_rate < -5:\n",
    "            priority = \"CRITICAL\"\n",
    "            alert_type = \"urgent\"\n",
    "        elif growth_rate < 0:\n",
    "            priority = \"HIGH\"\n",
    "            alert_type = \"warning\"\n",
    "        else:\n",
    "            priority = \"NORMAL\"\n",
    "            alert_type = \"info\"\n",
    "\n",
    "        payload = {\n",
    "            \"workflow_metadata\": {\n",
    "                \"workflow_name\": \"akij_sales_intelligence_multi_agent\",\n",
    "                \"workflow_version\": \"2.0\",\n",
    "                \"trigger_type\": \"scheduled_automated\",\n",
    "                \"organization\": \"Akij Resource\",\n",
    "                \"report_date\": datetime.now().strftime('%Y-%m-%d'),\n",
    "                \"report_time\": datetime.now().strftime('%H:%M:%S'),\n",
    "                \"generated_by\": \"Multi-Agent AI System\"\n",
    "            },\n",
    "            \"data_summary\": {\n",
    "                \"total_records\": len(self.raw_data),\n",
    "                \"date_range\": {\n",
    "                    \"start\": str(self.raw_data['date'].min().date()),\n",
    "                    \"end\": str(self.raw_data['date'].max().date())\n",
    "                },\n",
    "                \"total_revenue\": float(self.raw_data['revenue'].sum()),\n",
    "                \"total_profit\": float(self.raw_data['profit'].sum()),\n",
    "                \"avg_profit_margin\": float(self.raw_data['profit_margin'].mean()),\n",
    "                \"currency\": \"BDT (à§³)\"\n",
    "            },\n",
    "            \"analytics_results\": {\n",
    "                \"descriptive\": self.descriptive,\n",
    "                \"diagnostic\": self.diagnostic,\n",
    "                \"predictive\": self.predictive,\n",
    "                \"prescriptive\": self.prescriptive\n",
    "            },\n",
    "            \"alert_configuration\": {\n",
    "                \"priority\": priority,\n",
    "                \"alert_type\": alert_type,\n",
    "                \"notification_channels\": [\"email\", \"slack\", \"dashboard\"],\n",
    "                \"recipients\": [\n",
    "                    \"sales.director@akijresource.com\",\n",
    "                    \"cfo@akijresource.com\",\n",
    "                    \"analytics.team@akijresource.com\"\n",
    "                ]\n",
    "            },\n",
    "            \"actions_required\": [\n",
    "                {\n",
    "                    \"action_id\": f\"ACT{i+1:03d}\",\n",
    "                    \"priority\": action['priority'],\n",
    "                    \"description\": action['action'],\n",
    "                    \"timeline\": action['timeline'],\n",
    "                    \"expected_impact\": action['expected_impact'],\n",
    "                    \"status\": \"pending\",\n",
    "                    \"assigned_to\": \"sales_operations_team\"\n",
    "                }\n",
    "                for i, action in enumerate(self.prescriptive['immediate_actions'])\n",
    "            ],\n",
    "            \"webhook_config\": {\n",
    "                \"webhook_url\": \"https://mict4.app.n8n.cloud/home/webhook/akij-sales-intelligence\",\n",
    "                \"method\": \"POST\",\n",
    "                \"authentication\": \"bearer_token\",\n",
    "                \"retry_policy\": {\"max_retries\": 3, \"retry_interval\": 300}\n",
    "            },\n",
    "            \"integration_endpoints\": {\n",
    "                \"slack_webhook\": \"https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK\",\n",
    "                \"email_service\": \"smtp.akijresource.com\",\n",
    "                \"database_connection\": \"postgresql://analytics_db:5432/akij_sales\",\n",
    "                \"dashboard_api\": \"https://dashboard.akijresource.com/api/v1/update\"\n",
    "            },\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"webhook_ready\": True\n",
    "        }\n",
    "\n",
    "        return payload\n",
    "\n",
    "    def save_payload(self, filename: str = None) -> str:\n",
    "        \"\"\"Save payload JSON file\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"akij_payload.json\"\n",
    "        payload = self.generate_workflow_payload()\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "        return filename\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # STEP 2ï¸âƒ£ â€” Generate importable n8n workflow JSON\n",
    "    # ---------------------------------------------------------------------\n",
    "    def generate_n8n_workflow(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Convert payload into importable n8n workflow\"\"\"\n",
    "        p = payload\n",
    "\n",
    "        workflow = {\n",
    "            \"name\": f\"{p['workflow_metadata']['workflow_name']} (Auto Generated)\",\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"parameters\": {\"path\": \"akij-sales-intelligence\"},\n",
    "                    \"id\": \"Webhook_1\",\n",
    "                    \"name\": \"AI Report Webhook\",\n",
    "                    \"type\": \"n8n-nodes-base.webhook\",\n",
    "                    \"typeVersion\": 1,\n",
    "                    \"position\": [250, 300]\n",
    "                },\n",
    "                {\n",
    "                    \"parameters\": {\n",
    "                        \"functionCode\": (\n",
    "                            \"const payload = $json;\\n\"\n",
    "                            \"console.log('Payload received:', payload.workflow_metadata.workflow_name);\\n\"\n",
    "                            \"return [{ json: payload }];\"\n",
    "                        )\n",
    "                    },\n",
    "                    \"id\": \"Function_1\",\n",
    "                    \"name\": \"Process AI Report\",\n",
    "                    \"type\": \"n8n-nodes-base.function\",\n",
    "                    \"typeVersion\": 1,\n",
    "                    \"position\": [550, 300]\n",
    "                },\n",
    "                {\n",
    "                    \"parameters\": {\n",
    "                        \"url\": p[\"integration_endpoints\"][\"slack_webhook\"],\n",
    "                        \"method\": \"POST\",\n",
    "                        \"sendBody\": True,\n",
    "                        \"bodyParametersUi\": {\n",
    "                            \"parameter\": [\n",
    "                                {\n",
    "                                    \"name\": \"text\",\n",
    "                                    \"value\": f\"ğŸ“Š {p['workflow_metadata']['workflow_name']} report processed successfully!\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    \"id\": \"Slack_1\",\n",
    "                    \"name\": \"Notify Slack\",\n",
    "                    \"type\": \"n8n-nodes-base.httpRequest\",\n",
    "                    \"typeVersion\": 1,\n",
    "                    \"position\": [850, 300]\n",
    "                }\n",
    "            ],\n",
    "            \"connections\": {\n",
    "                \"AI Report Webhook\": {\"main\": [[{\"node\": \"Process AI Report\", \"type\": \"main\", \"index\": 0}]]},\n",
    "                \"Process AI Report\": {\"main\": [[{\"node\": \"Notify Slack\", \"type\": \"main\", \"index\": 0}]]}\n",
    "            },\n",
    "            \"active\": False,\n",
    "            \"settings\": {},\n",
    "            \"id\": str(int(datetime.now().timestamp()))\n",
    "        }\n",
    "\n",
    "        return workflow\n",
    "\n",
    "    def save_n8n_workflow(self, filename: str = None) -> str:\n",
    "        \"\"\"Save importable n8n workflow JSON\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"akij_n8n_workflow.json\"\n",
    "        payload = self.generate_workflow_payload()\n",
    "        workflow = self.generate_n8n_workflow(payload)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(workflow, f, indent=2)\n",
    "        return filename\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # STEP 3ï¸âƒ£ â€” Auto-generate both files\n",
    "    # ---------------------------------------------------------------------\n",
    "    def auto_generate(self) -> Dict[str, str]:\n",
    "        \"\"\"Generate both payload + workflow automatically\"\"\"\n",
    "        payload_file = self.save_payload()\n",
    "        workflow_file = self.save_n8n_workflow()\n",
    "        print(\"âœ… Payload saved:\", payload_file)\n",
    "        print(\"âœ… Importable workflow saved:\", workflow_file)\n",
    "        return {\"payload_file\": payload_file, \"workflow_file\": workflow_file}\n",
    "    \n",
    "print(\"\\nâœ… AGENT 5/OPS- n8n Workflow Builder Agent loaded successfully! \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c7118425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Payload saved: akij_payload.json\n",
      "âœ… Importable workflow saved: akij_n8n_workflow.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'payload_file': 'akij_payload.json',\n",
       " 'workflow_file': 'akij_n8n_workflow.json'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate n8n workflow files\n",
    "# Initialize the N8N workflow generator with all analyses and raw data\n",
    "n8n_generator = N8NWorkflowGenerator(\n",
    "    descriptive_analysis,\n",
    "    diagnostic_analysis,\n",
    "    predictive_analysis,\n",
    "    prescriptive_analysis,\n",
    "    sales_data\n",
    ")\n",
    "\n",
    "# Auto-generate both files\n",
    "n8n_generator.auto_generate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "010fe631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n8n_payload = n8n_generator.generate_workflow_payload()\n",
    "#workflow_filename = n8n_generator.save_workflow()\n",
    "\n",
    "# Generate only AI payload JSON\n",
    "#payload_filename = n8n_generator.save_payload()\n",
    "\n",
    "# Generate only n8n importable workflow\n",
    "#workflow_filename = n8n_generator.save_n8n_workflow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ffbb7456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… n8n Workflow Generated Successfully!\n",
      "\n",
      "ğŸ“¦ Workflow Configuration:\n",
      "   â€¢ Workflow Name: akij_sales_intelligence_multi_agent\n",
      "   â€¢ Organization: Akij Resource\n",
      "   â€¢ Report Date: 2025-11-20\n",
      "   â€¢ Priority Level: HIGH\n",
      "   â€¢ Alert Type: warning\n",
      "   â€¢ Actions Required: 2\n"
     ]
    }
   ],
   "source": [
    "n8n_payload = n8n_generator.generate_workflow_payload()\n",
    "\n",
    "print(f\"\\nâœ… n8n Workflow Generated Successfully!\")\n",
    "print(f\"\\nğŸ“¦ Workflow Configuration:\")\n",
    "print(f\"   â€¢ Workflow Name: {n8n_payload['workflow_metadata']['workflow_name']}\")\n",
    "print(f\"   â€¢ Organization: {n8n_payload['workflow_metadata']['organization']}\")\n",
    "print(f\"   â€¢ Report Date: {n8n_payload['workflow_metadata']['report_date']}\")\n",
    "print(f\"   â€¢ Priority Level: {n8n_payload['alert_configuration']['priority']}\")\n",
    "print(f\"   â€¢ Alert Type: {n8n_payload['alert_configuration']['alert_type']}\")\n",
    "print(f\"   â€¢ Actions Required: {len(n8n_payload['actions_required'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9ff4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"\\nğŸ“„ Workflow Payload Saved:\")  {\"payload_file\": payload_file, \"workflow_file\": workflow_file}\n",
    "#print(f\"   â€¢ Filename: {workflow_filename}\")\n",
    "#print(f\"   â€¢ File Size: {len(json.dumps(n8n_payload, default=str))} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a7ad2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”— Integration Endpoints Configured:\n",
      "   â€¢ slack_webhook: https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK\n",
      "   â€¢ email_service: smtp.akijresource.com\n",
      "   â€¢ database_connection: postgresql://analytics_db:5432/akij_sales\n",
      "   â€¢ dashboard_api: https://dashboard.akijresource.com/api/v1/update\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ”— Integration Endpoints Configured:\")\n",
    "for endpoint, url in n8n_payload['integration_endpoints'].items():\n",
    "    print(f\"   â€¢ {endpoint}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e2e993e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¨ Notification Channels:\n",
      "   â€¢ EMAIL\n",
      "   â€¢ SLACK\n",
      "   â€¢ DASHBOARD\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ“¨ Notification Channels:\")\n",
    "for channel in n8n_payload['alert_configuration']['notification_channels']:\n",
    "    print(f\"   â€¢ {channel.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e6d15957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ Webhook Configuration:\n",
      "   â€¢ URL: https://mict4.app.n8n.cloud/home/webhook/akij-sales-intelligence\n",
      "   â€¢ Method: POST\n",
      "   â€¢ Max Retries: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ’¡ Webhook Configuration:\")\n",
    "print(f\"   â€¢ URL: {n8n_payload['webhook_config']['webhook_url']}\")\n",
    "print(f\"   â€¢ Method: {n8n_payload['webhook_config']['method']}\")\n",
    "print(f\"   â€¢ Max Retries: {n8n_payload['webhook_config']['retry_policy']['max_retries']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e1d9c483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Sample Payload Preview (first 1000 chars):\n",
      "{\n",
      "  \"workflow_metadata\": {\n",
      "    \"workflow_name\": \"akij_sales_intelligence_multi_agent\",\n",
      "    \"workflow_version\": \"2.0\",\n",
      "    \"trigger_type\": \"scheduled_automated\",\n",
      "    \"organization\": \"Akij Resource\",\n",
      "    \"report_date\": \"2025-11-20\",\n",
      "    \"report_time\": \"23:31:20\",\n",
      "    \"generated_by\": \"Multi-Agent AI System\"\n",
      "  },\n",
      "  \"data_summary\": {\n",
      "    \"total_records\": 4000,\n",
      "    \"date_range\": {\n",
      "      \"start\": \"2023-11-21\",\n",
      "      \"end\": \"2025-11-20\"\n",
      "    },\n",
      "    \"total_revenue\": 224504337.22577766,\n",
      "    \"total_profit\": 86097591.68454546,\n",
      "    \"avg_profit_margin\": 34.94361302967179,\n",
      "    \"currency\": \"BDT (\\u09f3)\"\n",
      "  },\n",
      "  \"analytics_results\": {\n",
      "    \"descriptive\": {\n",
      "      \"agent_name\": \"Descriptive Analytics Agent - Akij Resource\",\n",
      "      \"timestamp\": \"2025-11-20T23:23:58.733095\",\n",
      "      \"overall_metrics\": {\n",
      "        \"total_revenue\": 224504337.23,\n",
      "        \"total_profit\": 86097591.68,\n",
      "        \"total_transactions\": 4000,\n",
      "        \"total_quantity_sold\": 1451602,\n",
      "        \"avg_transaction_value\": 56126.08,\n",
      "        \"avg_pro\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ“Š Sample Payload Preview (first 1000 chars):\")\n",
    "print(json.dumps(n8n_payload, indent=2, default=str)[:1000] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "46f1fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… ALL SECTIONS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ˆ Generated Deliverables:\n",
      "   1. Sales Data: akij_sales_data_complete.csv\n",
      "   2. n8n Workflow: akij_payload.json + akij_n8n_workflow.json\n",
      "   3. Complete Analytics: All 4 agents executed\n",
      "\n",
      "ğŸ¯ System Ready for Production Deployment!\n",
      "\n",
      "ğŸ“ˆ To Launch Chatbot Interface & Dashboard: CLI Run\n",
      "\n",
      " streamlit run chatbot_ui.py\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL SECTIONS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“ˆ Generated Deliverables:\")\n",
    "print(f\"   1. Sales Data: akij_sales_data_complete.csv\")\n",
    "print(f\"   2. n8n Workflow: akij_payload.json + akij_n8n_workflow.json\")\n",
    "print(f\"   3. Complete Analytics: All 4 agents executed\")\n",
    "print(f\"\\nğŸ¯ System Ready for Production Deployment!\")\n",
    "print(f\"\\nğŸ“ˆ To Launch Chatbot Interface & Dashboard: CLI Run\")\n",
    "print(f\"\\n streamlit run chatbot_ui.py\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "sales-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
